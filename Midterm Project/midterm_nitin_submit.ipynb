{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "midterm_nitin_submit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "conda_tensorflow_p36",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTcLyuxvVCYO",
        "colab_type": "text"
      },
      "source": [
        "##Step 1 Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdhaRTWBVGhY",
        "colab_type": "text"
      },
      "source": [
        "First step is to preprocess the EMBER dataset after installing the essential modules. The whole code was preprocessed on AWS Sagemaker."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gah4UHkTyQSb",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RuEiHFmTyQSl"
      },
      "source": [
        "# Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qC4rEtdVY0a",
        "colab_type": "text"
      },
      "source": [
        "Installing packages like Tensorflow,keras etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FTZeCD-YyQSl",
        "colab": {},
        "outputId": "73bdafcc-209f-465b-8e08-3164e4b3f605"
      },
      "source": [
        "#installing tensorflow\n",
        "!conda install tensorflow -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.5.12\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/ec2-user/anaconda3/envs/tensorflow_p36\n",
            "\n",
            "  added / updated specs: \n",
            "    - tensorflow\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _tflow_select-2.3.0        |              mkl           2 KB\n",
            "    protobuf-3.11.4            |   py36he6710b0_0         711 KB\n",
            "    markdown-3.1.1             |           py36_0         113 KB\n",
            "    google-pasta-0.2.0         |             py_0          44 KB\n",
            "    termcolor-1.1.0            |           py36_1           7 KB\n",
            "    tensorflow-estimator-2.0.0 |     pyh2649769_0         272 KB\n",
            "    astor-0.8.0                |           py36_0          45 KB\n",
            "    libprotobuf-3.11.4         |       hd408876_0         4.8 MB\n",
            "    keras-applications-1.0.8   |             py_0          33 KB\n",
            "    certifi-2020.4.5.1         |           py36_0         159 KB\n",
            "    c-ares-1.15.0              |    h7b6447c_1001         102 KB\n",
            "    setuptools-46.1.3          |           py36_0         663 KB\n",
            "    wrapt-1.12.1               |   py36h7b6447c_1          49 KB\n",
            "    keras-preprocessing-1.1.0  |             py_1          36 KB\n",
            "    tensorflow-base-2.0.0      |mkl_py36h9204916_0       100.9 MB\n",
            "    tensorboard-2.0.0          |     pyhb38c66f_1         3.3 MB\n",
            "    tensorflow-2.0.0           |mkl_py36hef7ec59_0           3 KB\n",
            "    gast-0.2.2                 |           py36_0         138 KB\n",
            "    opt_einsum-3.1.0           |             py_0          54 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       111.5 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _tflow_select:        2.3.0-mkl               \n",
            "    absl-py:              0.9.0-py36_0            \n",
            "    astor:                0.8.0-py36_0            \n",
            "    c-ares:               1.15.0-h7b6447c_1001    \n",
            "    gast:                 0.2.2-py36_0            \n",
            "    google-pasta:         0.2.0-py_0              \n",
            "    grpcio:               1.14.1-py36h9ba97e2_0   \n",
            "    keras-applications:   1.0.8-py_0              \n",
            "    keras-preprocessing:  1.1.0-py_1              \n",
            "    libprotobuf:          3.11.4-hd408876_0       \n",
            "    markdown:             3.1.1-py36_0            \n",
            "    opt_einsum:           3.1.0-py_0              \n",
            "    protobuf:             3.11.4-py36he6710b0_0   \n",
            "    tensorboard:          2.0.0-pyhb38c66f_1      \n",
            "    tensorflow:           2.0.0-mkl_py36hef7ec59_0\n",
            "    tensorflow-base:      2.0.0-mkl_py36h9204916_0\n",
            "    tensorflow-estimator: 2.0.0-pyh2649769_0      \n",
            "    termcolor:            1.1.0-py36_1            \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    certifi:              2019.11.28-py36_0        --> 2020.4.5.1-py36_0    \n",
            "    setuptools:           39.1.0-py36_0            --> 46.1.3-py36_0        \n",
            "    six:                  1.11.0-py36h372c433_1    --> 1.14.0-py36_0        \n",
            "    wrapt:                1.10.11-py36h28b7045_0   --> 1.12.1-py36h7b6447c_1\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "_tflow_select-2.3.0  | 2 KB      | ##################################### | 100% \n",
            "protobuf-3.11.4      | 711 KB    | ##################################### | 100% \n",
            "markdown-3.1.1       | 113 KB    | ##################################### | 100% \n",
            "google-pasta-0.2.0   | 44 KB     | ##################################### | 100% \n",
            "termcolor-1.1.0      | 7 KB      | ##################################### | 100% \n",
            "tensorflow-estimator | 272 KB    | ##################################### | 100% \n",
            "astor-0.8.0          | 45 KB     | ##################################### | 100% \n",
            "libprotobuf-3.11.4   | 4.8 MB    | ##################################### | 100% \n",
            "keras-applications-1 | 33 KB     | ##################################### | 100% \n",
            "certifi-2020.4.5.1   | 159 KB    | ##################################### | 100% \n",
            "c-ares-1.15.0        | 102 KB    | ##################################### | 100% \n",
            "setuptools-46.1.3    | 663 KB    | ##################################### | 100% \n",
            "wrapt-1.12.1         | 49 KB     | ##################################### | 100% \n",
            "keras-preprocessing- | 36 KB     | ##################################### | 100% \n",
            "tensorflow-base-2.0. | 100.9 MB  | ##################################### | 100% \n",
            "tensorboard-2.0.0    | 3.3 MB    | ##################################### | 100% \n",
            "tensorflow-2.0.0     | 3 KB      | ##################################### | 100% \n",
            "gast-0.2.2           | 138 KB    | ##################################### | 100% \n",
            "opt_einsum-3.1.0     | 54 KB     | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d9poc6bPyQSt",
        "colab": {},
        "outputId": "11ca74b3-5fef-427b-805f-2248b4554790"
      },
      "source": [
        "!conda install keras -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.5.12\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/ec2-user/anaconda3/envs/tensorflow_p36\n",
            "\n",
            "  added / updated specs: \n",
            "    - keras\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    keras-2.3.1                |                0          12 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    keras:      2.3.1-0     \n",
            "    keras-base: 2.3.1-py36_0\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "keras-2.3.1          | 12 KB     | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VmInL3h7yQS-",
        "colab": {},
        "outputId": "4e40185f-2bf8-472a-c217-53162ba03f69"
      },
      "source": [
        "!conda install numpy -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: done\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 4.5.12\n",
            "  latest version: 4.8.3\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /home/ec2-user/anaconda3/envs/tensorflow_p36\n",
            "\n",
            "  added / updated specs: \n",
            "    - numpy\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    numpy-1.18.1               |   py36h4f9e942_0           5 KB\n",
            "    numpy-base-1.18.1          |   py36hde5b4d6_1         5.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         5.2 MB\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    numpy:      1.16.4-py36h7e9f1db_0 --> 1.18.1-py36h4f9e942_0\n",
            "    numpy-base: 1.16.4-py36hde5b4d6_0 --> 1.18.1-py36hde5b4d6_1\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "numpy-1.18.1         | 5 KB      | ##################################### | 100% \n",
            "numpy-base-1.18.1    | 5.2 MB    | ##################################### | 100% \n",
            "Preparing transaction: done\n",
            "Verifying transaction: done\n",
            "Executing transaction: done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_AitElUtw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuES_hm1Utw_",
        "colab_type": "code",
        "colab": {},
        "outputId": "7985222b-6cde-4375-c568-d6a122c045f8"
      },
      "source": [
        "tf.keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow_core.keras' from '/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/api/_v2/keras/__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DknxlJKgyQTE"
      },
      "source": [
        "# Loading the data to AWS Sagemaker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "isuQh6efEzwZ",
        "outputId": "a51be89c-fa51-4e2c-cc7e-92da13e51985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "!wget --no-check-certificate https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 17:04:51--  https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2\n",
            "Resolving pubdata.endgame.com (pubdata.endgame.com)... 64.250.189.21\n",
            "Connecting to pubdata.endgame.com (pubdata.endgame.com)|64.250.189.21|:443... connected.\n",
            "WARNING: cannot verify pubdata.endgame.com's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1751237573 (1.6G) [application/octet-stream]\n",
            "Saving to: ‘ember_dataset_2017_2.tar.bz2’\n",
            "\n",
            "ember_dataset_2017_ 100%[===================>]   1.63G  60.6MB/s    in 38s     \n",
            "\n",
            "2020-04-12 17:05:29 (43.7 MB/s) - ‘ember_dataset_2017_2.tar.bz2’ saved [1751237573/1751237573]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xThN4KybFKyA",
        "colab": {}
      },
      "source": [
        "!bzip2 -d ember_dataset_2017_2.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pT2td_MRFU7a",
        "outputId": "c020aa9b-82bd-47b3-971a-9fe7994ec137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "!tar -xvf ember_dataset_2017_2.tar"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ember_2017_2/\n",
            "ember_2017_2/train_features_1.jsonl\n",
            "ember_2017_2/train_features_0.jsonl\n",
            "ember_2017_2/train_features_3.jsonl\n",
            "ember_2017_2/test_features.jsonl\n",
            "ember_2017_2/train_features_5.jsonl\n",
            "ember_2017_2/train_features_4.jsonl\n",
            "ember_2017_2/train_features_2.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mY90MRaUFi-w",
        "colab": {}
      },
      "source": [
        "!rm ember_dataset_2017_2.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njc40X6Oaa-d",
        "outputId": "f5019c90-8f7a-4bc6-d3f1-55b40855832d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "!wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!cp -r ember-master/* .\n",
        "!rm -r ember-master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 17:20:52--  https://github.com/endgameinc/ember/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/endgameinc/ember/zip/master [following]\n",
            "--2020-04-12 17:20:52--  https://codeload.github.com/endgameinc/ember/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [  <=>               ]  11.22M  14.3MB/s    in 0.8s    \n",
            "\n",
            "2020-04-12 17:20:53 (14.3 MB/s) - ‘master.zip’ saved [11769324]\n",
            "\n",
            "Archive:  master.zip\n",
            "f9a018632ba108b4e25c33d6c3e2e7a7c4487f58\n",
            "   creating: ember-master/\n",
            "  inflating: ember-master/LICENSE.txt  \n",
            "  inflating: ember-master/README.md  \n",
            "   creating: ember-master/ember/\n",
            "  inflating: ember-master/ember/__init__.py  \n",
            "  inflating: ember-master/ember/features.py  \n",
            "   creating: ember-master/licenses/\n",
            "  inflating: ember-master/licenses/AGPL-LICENSE-3.0.txt  \n",
            "  inflating: ember-master/licenses/MIT-LICENSE.txt  \n",
            "   creating: ember-master/malconv/\n",
            "  inflating: ember-master/malconv/README.md  \n",
            "  inflating: ember-master/malconv/malconv.h5  \n",
            "  inflating: ember-master/malconv/malconv.py  \n",
            "  inflating: ember-master/malconv/multi_gpu.py  \n",
            "  inflating: ember-master/requirements.txt  \n",
            "  inflating: ember-master/requirements_conda.txt  \n",
            "  inflating: ember-master/requirements_notebook.txt  \n",
            "   creating: ember-master/resources/\n",
            "  inflating: ember-master/resources/ember-notebook.ipynb  \n",
            "  inflating: ember-master/resources/ember2018-notebook.ipynb  \n",
            "  inflating: ember-master/resources/logo.png  \n",
            "   creating: ember-master/scripts/\n",
            "  inflating: ember-master/scripts/classify_binaries.py  \n",
            "  inflating: ember-master/scripts/train_ember.py  \n",
            "  inflating: ember-master/setup.py   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gsm-JuY9am2N",
        "outputId": "4ac6191f-6f24-4529-e55f-43c674d2fe9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!conda install -r requirements.txt -y\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: conda [-h] [-V] command ...\n",
            "conda: error: unrecognized arguments: -r\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing requirements to ember.egg-info/requires.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/ember-0.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.6.egg\n",
            "Removing /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ember-0.1.0-py3.6.egg\n",
            "Copying ember-0.1.0-py3.6.egg to /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "ember 0.1.0 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ember-0.1.0-py3.6.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Searching for scikit-learn==0.22.1\n",
            "Best match: scikit-learn 0.22.1\n",
            "Adding scikit-learn 0.22.1 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for lightgbm==2.3.1\n",
            "Best match: lightgbm 2.3.1\n",
            "Adding lightgbm 2.3.1 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for pandas==0.24.2\n",
            "Best match: pandas 0.24.2\n",
            "Adding pandas 0.24.2 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for numpy==1.18.1\n",
            "Best match: numpy 1.18.1\n",
            "Adding numpy 1.18.1 to easy-install.pth file\n",
            "Installing f2py script to /home/ec2-user/anaconda3/envs/tensorflow_p36/bin\n",
            "Installing f2py3 script to /home/ec2-user/anaconda3/envs/tensorflow_p36/bin\n",
            "Installing f2py3.6 script to /home/ec2-user/anaconda3/envs/tensorflow_p36/bin\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for tqdm==4.45.0\n",
            "Best match: tqdm 4.45.0\n",
            "Adding tqdm 4.45.0 to easy-install.pth file\n",
            "Installing tqdm script to /home/ec2-user/anaconda3/envs/tensorflow_p36/bin\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for lief==0.10.1\n",
            "Best match: lief 0.10.1\n",
            "Adding lief 0.10.1 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for python-dateutil==2.7.3\n",
            "Best match: python-dateutil 2.7.3\n",
            "Adding python-dateutil 2.7.3 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for pytz==2018.4\n",
            "Best match: pytz 2018.4\n",
            "Adding pytz 2018.4 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Searching for six==1.14.0\n",
            "Best match: six 1.14.0\n",
            "Adding six 1.14.0 to easy-install.pth file\n",
            "\n",
            "Using /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "21AgLvOuarKl",
        "outputId": "503a9889-6a60-4d2e-c06f-95e8782cb2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        }
      },
      "source": [
        "import ember\n",
        "ember.create_vectorized_features(\"ember_2017_2/\")\n",
        "ember.create_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "Vectorizing training set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900000/900000 [23:29<00:00, 638.59it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vectorizing test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [06:30<00:00, 511.92it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>subset</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>eac8ddb4970f8af985742973d6f0e06902d42a3684d791...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8d063d2a16cd286d9c85f07fc33ab1fcaeb24a5a92e1c6...</td>\n",
              "      <td>2007-04</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>f725cee174223b6fbc49e2ba9a30c69c48b548fc5b382f...</td>\n",
              "      <td>2007-04</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ca651181cd18cf091e1860a4c8570624a593a711c5a112...</td>\n",
              "      <td>2007-06</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2fcc0cdc69773cd830805147fb6a81af34c14725a5a4cf...</td>\n",
              "      <td>2007-08</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9997044147ec7f5ede801c6cdcc164f70273b14a6c23ac...</td>\n",
              "      <td>2007-08</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100fc85f8888a3dbe7e59a00bec5f957b53dc44dab74e5...</td>\n",
              "      <td>2007-09</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>7c20fb241ae42b1fd455e6cd4619fa3bb02f1044bf0e83...</td>\n",
              "      <td>2007-09</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ae3f3cf73b5aa186a7863e055051594392224aaeed26e9...</td>\n",
              "      <td>2007-09</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>f0cd98c05c9952b4ed7bf4415de927853fce0bb78318b9...</td>\n",
              "      <td>2007-09</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>035bcc115025cb119fef9bcf1ba623d64b1bee851cedf0...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2e8a5ecf3714ccf7a2a9c3a3728331ec4f0110cde6a698...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4525f8d52a8e4c5a3e719882dcfa5d54fabbae62ad65ae...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4dc8d3762e0b568716647f2e78b1ff46bce1ec336f6d4a...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>64a732bbe3f84671d8c4e4eaf8a759f66d7aaf16d61dec...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>7d284be67f33b37154e86e5a6d12c5f54d4e7db724c80d...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>afe4584d19981f8b0d15e5e4677b112695c09a41e10a53...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>c9baf17349daecbbbf42dc0883847c0539509a638cc4fa...</td>\n",
              "      <td>2007-10</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>46d8f613e80736e0a8329c3f97c1a4d8b584d731dc3258...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>70a4d39a0cd908b7fdc05bbb44213dee64345c00155821...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>7da510ef340e23612112e515174191ad79443ad0a3f2ee...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>83ff34d3c9395d6d7516f343052fe279c1349e1d24b199...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>91070da8b49bde9506c4da8698f2cd1d7e166f1e53635a...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>9d22c2557420550f1f92be1efb8ea6967f8d8b48055828...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>a8a94be3117bdd9a3d86a9c12488604179e67114f3ca98...</td>\n",
              "      <td>2007-11</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099970</th>\n",
              "      <td>ffec4f403020c1550e84bf21b261edddb7b3595fbf9dd4...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099971</th>\n",
              "      <td>ffec657610f430fb976317fa5e510dee350cc20781964d...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099972</th>\n",
              "      <td>ffed4e25dde951c41f1f63052a918cc5b8c5c1343effb1...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099973</th>\n",
              "      <td>ffee6fe924553ed5ce83d76dfca9aa8b842c5a3f36f30e...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099974</th>\n",
              "      <td>ffef372f53d3edfb940dcc6fc9e03b70e842582811e17f...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099975</th>\n",
              "      <td>fff0313f55f1fbf3a44d1cd8930dafebc955e9362d6e40...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099976</th>\n",
              "      <td>fff1cd15ebb3b6ade810fa2942e24979bf07777309c813...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099977</th>\n",
              "      <td>fff20df969e47b57e20bc6b0d27d46037e0c9942a7312b...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099978</th>\n",
              "      <td>fff22f32f6c12fb33d5734700953d8ca15cb259e3deab7...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099979</th>\n",
              "      <td>fff2d07f82d176cdc86cb4c86af36c51da089f7a39c4ff...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099980</th>\n",
              "      <td>fff374fa5d0861043551368a2020a07306fc78a8578f50...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099981</th>\n",
              "      <td>fff42aad65d24cb8612a8da29329d7c75088149558dd38...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099982</th>\n",
              "      <td>fff45e7a2bde5a97f62333fb8071aab4c409da0c042782...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099983</th>\n",
              "      <td>fff4a8f38a44f5594830ece39e9bb8101d15fb873d15e1...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099984</th>\n",
              "      <td>fff518919ed7f849e87732350a00f9afeb5977a483990a...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099985</th>\n",
              "      <td>fff558d65316fd6e53cfdceb34c224c50f3cc0eddfe1af...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099986</th>\n",
              "      <td>fff68023d2539c93945a2930e96ca6bd7c81a42f37e03f...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099987</th>\n",
              "      <td>fff714f89fc507979390d2e5e3505b82096028fb0c5c9c...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099988</th>\n",
              "      <td>fff88f594270afff4c2ec11f77ebf156f6949d76c4634f...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099989</th>\n",
              "      <td>fff97c4a51875f4523eac6ea522476e0fc08637e758de0...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099990</th>\n",
              "      <td>fff999623217a8d3192a8737924e3d115c9de10ff33341...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099991</th>\n",
              "      <td>fff9bc8ecbb4d4f7897239c09b0e16d939863dd1355305...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099992</th>\n",
              "      <td>fffa1f9a0862bd4067d93518ec73826eb8d9b552e2da7f...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099993</th>\n",
              "      <td>fffb683975d2997b838df2235113ca6431aef57d98cfcc...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099994</th>\n",
              "      <td>fffdb2eb5c5d156cd383ac6c146d1f373ca3bdef194dd6...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099995</th>\n",
              "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099996</th>\n",
              "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099997</th>\n",
              "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099998</th>\n",
              "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099999</th>\n",
              "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    sha256 appeared subset  \\\n",
              "0        0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  2006-12  train   \n",
              "1        d4206650743b3d519106dea10a38a55c30467c3d9f7875...  2006-12  train   \n",
              "2        c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  2007-01  train   \n",
              "3        7f513818bcc276c531af2e641c597744da807e21cc1160...  2007-02  train   \n",
              "4        ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  2007-02  train   \n",
              "5        eac8ddb4970f8af985742973d6f0e06902d42a3684d791...  2007-02  train   \n",
              "6        8d063d2a16cd286d9c85f07fc33ab1fcaeb24a5a92e1c6...  2007-04  train   \n",
              "7        f725cee174223b6fbc49e2ba9a30c69c48b548fc5b382f...  2007-04  train   \n",
              "8        ca651181cd18cf091e1860a4c8570624a593a711c5a112...  2007-06  train   \n",
              "9        2fcc0cdc69773cd830805147fb6a81af34c14725a5a4cf...  2007-08  train   \n",
              "10       9997044147ec7f5ede801c6cdcc164f70273b14a6c23ac...  2007-08  train   \n",
              "11       100fc85f8888a3dbe7e59a00bec5f957b53dc44dab74e5...  2007-09  train   \n",
              "12       7c20fb241ae42b1fd455e6cd4619fa3bb02f1044bf0e83...  2007-09  train   \n",
              "13       ae3f3cf73b5aa186a7863e055051594392224aaeed26e9...  2007-09  train   \n",
              "14       f0cd98c05c9952b4ed7bf4415de927853fce0bb78318b9...  2007-09  train   \n",
              "15       035bcc115025cb119fef9bcf1ba623d64b1bee851cedf0...  2007-10  train   \n",
              "16       2e8a5ecf3714ccf7a2a9c3a3728331ec4f0110cde6a698...  2007-10  train   \n",
              "17       4525f8d52a8e4c5a3e719882dcfa5d54fabbae62ad65ae...  2007-10  train   \n",
              "18       4dc8d3762e0b568716647f2e78b1ff46bce1ec336f6d4a...  2007-10  train   \n",
              "19       64a732bbe3f84671d8c4e4eaf8a759f66d7aaf16d61dec...  2007-10  train   \n",
              "20       7d284be67f33b37154e86e5a6d12c5f54d4e7db724c80d...  2007-10  train   \n",
              "21       afe4584d19981f8b0d15e5e4677b112695c09a41e10a53...  2007-10  train   \n",
              "22       c9baf17349daecbbbf42dc0883847c0539509a638cc4fa...  2007-10  train   \n",
              "23       46d8f613e80736e0a8329c3f97c1a4d8b584d731dc3258...  2007-11  train   \n",
              "24       70a4d39a0cd908b7fdc05bbb44213dee64345c00155821...  2007-11  train   \n",
              "25       7da510ef340e23612112e515174191ad79443ad0a3f2ee...  2007-11  train   \n",
              "26       83ff34d3c9395d6d7516f343052fe279c1349e1d24b199...  2007-11  train   \n",
              "27       91070da8b49bde9506c4da8698f2cd1d7e166f1e53635a...  2007-11  train   \n",
              "28       9d22c2557420550f1f92be1efb8ea6967f8d8b48055828...  2007-11  train   \n",
              "29       a8a94be3117bdd9a3d86a9c12488604179e67114f3ca98...  2007-11  train   \n",
              "...                                                    ...      ...    ...   \n",
              "1099970  ffec4f403020c1550e84bf21b261edddb7b3595fbf9dd4...  2017-12   test   \n",
              "1099971  ffec657610f430fb976317fa5e510dee350cc20781964d...  2017-12   test   \n",
              "1099972  ffed4e25dde951c41f1f63052a918cc5b8c5c1343effb1...  2017-12   test   \n",
              "1099973  ffee6fe924553ed5ce83d76dfca9aa8b842c5a3f36f30e...  2017-12   test   \n",
              "1099974  ffef372f53d3edfb940dcc6fc9e03b70e842582811e17f...  2017-12   test   \n",
              "1099975  fff0313f55f1fbf3a44d1cd8930dafebc955e9362d6e40...  2017-12   test   \n",
              "1099976  fff1cd15ebb3b6ade810fa2942e24979bf07777309c813...  2017-12   test   \n",
              "1099977  fff20df969e47b57e20bc6b0d27d46037e0c9942a7312b...  2017-12   test   \n",
              "1099978  fff22f32f6c12fb33d5734700953d8ca15cb259e3deab7...  2017-12   test   \n",
              "1099979  fff2d07f82d176cdc86cb4c86af36c51da089f7a39c4ff...  2017-12   test   \n",
              "1099980  fff374fa5d0861043551368a2020a07306fc78a8578f50...  2017-12   test   \n",
              "1099981  fff42aad65d24cb8612a8da29329d7c75088149558dd38...  2017-12   test   \n",
              "1099982  fff45e7a2bde5a97f62333fb8071aab4c409da0c042782...  2017-12   test   \n",
              "1099983  fff4a8f38a44f5594830ece39e9bb8101d15fb873d15e1...  2017-12   test   \n",
              "1099984  fff518919ed7f849e87732350a00f9afeb5977a483990a...  2017-12   test   \n",
              "1099985  fff558d65316fd6e53cfdceb34c224c50f3cc0eddfe1af...  2017-12   test   \n",
              "1099986  fff68023d2539c93945a2930e96ca6bd7c81a42f37e03f...  2017-12   test   \n",
              "1099987  fff714f89fc507979390d2e5e3505b82096028fb0c5c9c...  2017-12   test   \n",
              "1099988  fff88f594270afff4c2ec11f77ebf156f6949d76c4634f...  2017-12   test   \n",
              "1099989  fff97c4a51875f4523eac6ea522476e0fc08637e758de0...  2017-12   test   \n",
              "1099990  fff999623217a8d3192a8737924e3d115c9de10ff33341...  2017-12   test   \n",
              "1099991  fff9bc8ecbb4d4f7897239c09b0e16d939863dd1355305...  2017-12   test   \n",
              "1099992  fffa1f9a0862bd4067d93518ec73826eb8d9b552e2da7f...  2017-12   test   \n",
              "1099993  fffb683975d2997b838df2235113ca6431aef57d98cfcc...  2017-12   test   \n",
              "1099994  fffdb2eb5c5d156cd383ac6c146d1f373ca3bdef194dd6...  2017-12   test   \n",
              "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  2017-12   test   \n",
              "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  2017-12   test   \n",
              "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  2017-12   test   \n",
              "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  2017-12   test   \n",
              "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  2017-12   test   \n",
              "\n",
              "         label  \n",
              "0            0  \n",
              "1            0  \n",
              "2            0  \n",
              "3            0  \n",
              "4            0  \n",
              "5            0  \n",
              "6            0  \n",
              "7            0  \n",
              "8            0  \n",
              "9            0  \n",
              "10           0  \n",
              "11           0  \n",
              "12           0  \n",
              "13           0  \n",
              "14           0  \n",
              "15           0  \n",
              "16           0  \n",
              "17           0  \n",
              "18           0  \n",
              "19           0  \n",
              "20           0  \n",
              "21           0  \n",
              "22           0  \n",
              "23           0  \n",
              "24           0  \n",
              "25           0  \n",
              "26           0  \n",
              "27           0  \n",
              "28           0  \n",
              "29           0  \n",
              "...        ...  \n",
              "1099970      0  \n",
              "1099971      1  \n",
              "1099972      0  \n",
              "1099973      1  \n",
              "1099974      0  \n",
              "1099975      0  \n",
              "1099976      0  \n",
              "1099977      0  \n",
              "1099978      1  \n",
              "1099979      0  \n",
              "1099980      0  \n",
              "1099981      0  \n",
              "1099982      1  \n",
              "1099983      0  \n",
              "1099984      1  \n",
              "1099985      0  \n",
              "1099986      1  \n",
              "1099987      0  \n",
              "1099988      1  \n",
              "1099989      0  \n",
              "1099990      1  \n",
              "1099991      1  \n",
              "1099992      1  \n",
              "1099993      1  \n",
              "1099994      1  \n",
              "1099995      0  \n",
              "1099996      1  \n",
              "1099997      0  \n",
              "1099998      1  \n",
              "1099999      1  \n",
              "\n",
              "[1100000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G2mU4ZA3yQU-"
      },
      "source": [
        "# Model Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcak41n7V0sm",
        "colab_type": "text"
      },
      "source": [
        "Below is the model structure of the tensorflow ML model with keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-m02QptdKa01",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  feature_size=2381\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  #Model architecture\n",
        "  from tensorflow.keras import layers\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1500, activation='relu'))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R28fXRPXpqix",
        "outputId": "d8aa4712-0c22-4482-c80f-02fb7b186a87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model = make_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 1, 2381)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 1500)           3573000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1500)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 1)              1501      \n",
            "=================================================================\n",
            "Total params: 3,574,501\n",
            "Trainable params: 3,574,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X0NbaX3rVivv",
        "colab": {},
        "outputId": "4bb40779-aad5-4673-ab84-2ec815d08ce9"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ArjnH4jzy6sv"
      },
      "source": [
        "# Standardizing Data and Taking Relevent Samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v4z0UiAvKurJ"
      },
      "source": [
        "I have used  the library lief to do vectorizing the features. Now We must normalize the data values. \n",
        "Since the data is too large to load into memory and fit to the scaler in the same runtime execution, we can prep the data in steps. I used different instances starting from medium to big to execute teh code as the files was too large and i was getting lots of errors for memory. I tried to use AWS educate account first but later decided to use AWS free account to create big instances which helpe me run the model fast."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AaECqG9ZLTpe",
        "colab": {},
        "outputId": "f052be79-d808-4a8d-c408-8c3523435a9d"
      },
      "source": [
        "import ember\n",
        "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"ember_2017_2/\")\n",
        "metadata_dataframe = ember.read_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RjLGCdB5LaQL",
        "colab": {}
      },
      "source": [
        "labelrows = (y_train != -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iEqTXUSALcSq",
        "colab": {}
      },
      "source": [
        "X_train = X_train[labelrows]\n",
        "y_train = y_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "owEOkpzwLe3q",
        "colab": {}
      },
      "source": [
        "#run this to make a h5 file in the session in case the ram crashes\n",
        "import h5py\n",
        "h5f = h5py.File('X_train.h5', 'w')\n",
        "h5f.create_dataset('X_train', data=X_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IPJh6QBnLhTk",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('y_train.h5', 'w')\n",
        "h5f.create_dataset('y_train', data=y_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpaeAewyUtxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('X_test.h5', 'w')\n",
        "h5f.create_dataset('X_test', data=X_test)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NjdrMdu0LruP",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('y_test.h5', 'w')\n",
        "h5f.create_dataset('y_test', data=y_test)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Ntfvn9Utxs",
        "colab_type": "code",
        "colab": {},
        "outputId": "83c1b6ed-6db4-4001-933b-817e4eade102"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fvk-ZuiYL2EL",
        "colab": {}
      },
      "source": [
        "#by checking the size of y_train, we find that there's 600k labels. Now, We will partial fit the standardScaler to avoid overloading the memory.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler()\n",
        "\n",
        "for x in range(0,600000,100000):\n",
        "  mms.partial_fit(X_train[x:x+100000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ym9nfJi1L2G7",
        "colab": {}
      },
      "source": [
        "#do this in case the ram crashes...\n",
        "with open(\"mms_scaler\",\"wb\") as f:\n",
        "  import pickle\n",
        "  pickle.dump(mms,f)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OUii2H2aL2Jw",
        "colab": {}
      },
      "source": [
        "#transform the data\n",
        "X_train = mms.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kqd-HDjc1ZH2",
        "colab": {}
      },
      "source": [
        "#reshape data to have 3 channels...\n",
        "import numpy as np\n",
        "X_train = np.reshape(X_train,(-1,1,2381))\n",
        "y_train = np.reshape(y_train,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "baHbs_i2utiD"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VIHRJB4LGY5Y"
      },
      "source": [
        "Training is done sevaral times and later came to this 1 epoch value training model because there was lots of testing hyperparameters. However, here is the execution code minus any outputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j64uLJ_kOHaR",
        "colab": {},
        "outputId": "b32741e5-f29a-4898-cc0b-ecc77d23f275"
      },
      "source": [
        "#%tensorflow_version 2.0.0\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "pkl_base=\"data/\"\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=256,\n",
        "                epochs=1,\n",
        "                  validation_data =((X_train[600000-120000:600000],y_train[600000-120000:600000]))\n",
        "                  )\n",
        "model_name=\"my_model2.h5\"\n",
        "model_weights=\"weights2.h5\"\n",
        "model.save(pkl_base+model_name)\n",
        "model.save_weights(pkl_base+model_weights)\n",
        "print(model_name,model_weights,\" are saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 600000 samples, validate on 120000 samples\n",
            "600000/600000 [==============================] - 122s 204us/sample - loss: 3.4241 - accuracy: 0.9454 - auc_1: 0.9550 - precision_1: 0.9458 - val_loss: 1.6755 - val_accuracy: 0.9810 - val_auc_1: 0.9859 - val_precision_1: 0.9933\n",
            "my_model2.h5 weights2.h5  are saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RI_3QCb9GfCp"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0isIMAN5ssLP",
        "colab": {}
      },
      "source": [
        "#read to avoid having to filter the data for labeled samples again\n",
        "import h5py\n",
        "h5f = h5py.File('X_test.h5','r')\n",
        "X_test = h5f['X_test'][:]\n",
        "h5f.close()\n",
        "#read to avoid having to filter the data for labeled samples again\n",
        "import h5py\n",
        "h5f = h5py.File('y_test.h5','r')\n",
        "y_test = h5f['y_test'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gNknd57Fs4fo",
        "colab": {}
      },
      "source": [
        "#converting testing data too\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler()\n",
        "\n",
        "X_test = mms.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEJ-6NAX9J25",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_test = np.reshape(X_test,(-1,1,2381))\n",
        "y_test = np.reshape(y_test,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "--nOWRR3uS2o",
        "outputId": "96586112-814b-4d6d-87aa-8b60db643656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "model = tf.keras.models.load_model(\"data/\"+'my_model2.h5')\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "results =model.evaluate(X_test,y_test)\n",
        "print(\"loss: %gl,acc: %gl\"%(results[0],results[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 19s 93us/sample - loss: 3.1359 - accuracy: 0.9081 - auc_2: 0.9384 - precision_2: 0.9632\n",
            "loss: 3.13591l,acc: 0.908065l\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pvfz3REhsGu2",
        "colab": {}
      },
      "source": [
        "pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rJhQXhTsshs_",
        "colab": {}
      },
      "source": [
        "y_test = np.reshape(y_test,(-1))\n",
        "pred = np.reshape(pred,(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dvwDZZLpswCM",
        "outputId": "b27bab35-415f-4e32-95a1-5032a432d86f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "y_test,pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 1., 0., ..., 0., 1., 1.], dtype=float32),\n",
              " array([1., 1., 0., ..., 0., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pVdaI13etd0S",
        "outputId": "05d572ab-ce37-4334-9f0d-3682cf867053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "y_test.shape,pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((200000,), (200000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VfehWTxvr2M4",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "fpr, tpr, tresh = metrics.roc_curve(y_test,pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "STmrqc2dt6Lo",
        "outputId": "cd34431a-8904-4cf2-b255-9e23ae05ed43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "metrics.auc(fpr,tpr)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9628303509499998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_qFwKy32u4bw",
        "colab": {}
      },
      "source": [
        "y_test_int = np.asarray(y_test,dtype=int)\n",
        "pred_int=np.asarray(pred,dtype=int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QH74vbSkuqIn",
        "outputId": "4c4b9f0e-8b17-4699-c096-40f8acf47d9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "fscore = f1_score(y_test_int, pred_int) \n",
        "fscore"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8582682909037858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZupBim7BCEwX",
        "colab": {}
      },
      "source": [
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SRfFWn2nBuJ5",
        "outputId": "3fab27ab-a5f8-4b8b-b46d-295057cbb5ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "precision = sklearn.metrics.precision_score(y_test_int,pred_int)\n",
        "precision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9777797665469143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZsOWaXVvWCz",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test_int,pred_int,labels=[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oDT6Hbnjvx7Z",
        "outputId": "5c664625-803c-479f-8c01-af09be413fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(cm,columns=['pred_benign','pred_malicious'],index=['is_benign','is_malicious'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_benign</th>\n",
              "      <th>pred_malicious</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>is_benign</th>\n",
              "      <td>98262</td>\n",
              "      <td>1738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_malicious</th>\n",
              "      <td>23521</td>\n",
              "      <td>76479</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pred_benign  pred_malicious\n",
              "is_benign           98262            1738\n",
              "is_malicious        23521           76479"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gmgOzZVK0ni6",
        "colab": {}
      },
      "source": [
        "#!wget https://the.earth.li/~sgtatham/putty/latest/w32/putty.exe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LGE4nnCl3Qi0",
        "colab": {}
      },
      "source": [
        "!cp drive/My\\ Drive/data/pickles/my_model_test-tpu3.h5 model.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8CUbPxMdzBNg",
        "colab": {}
      },
      "source": [
        "def test_pefile(pefile):\n",
        "  try:\n",
        "    import ember\n",
        "  except:\n",
        "    !wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "    !unzip master.zip\n",
        "    !rm master.zip\n",
        "    !cp -r ember-master/* .\n",
        "    !rm -r ember-master\n",
        "    !pip install -r requirements.txt\n",
        "    !python setup.py install\n",
        "    import ember\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  import tensorflow as tf\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "  with open(\"mms_scaler\",\"rb\") as f:\n",
        "    import pickle\n",
        "    mms = pickle.load(f)\n",
        "    f.close()\n",
        "  \n",
        "  sample_data = open(pefile, \"rb\").read()\n",
        "  extractor = ember.PEFeatureExtractor(2)\n",
        "  sample_data = np.array(extractor.feature_vector(sample_data), dtype=np.float32)\n",
        "  sample_data = mms.transform([sample_data])\n",
        "  sample_data = np.reshape(sample_data,(-1,1,2381))\n",
        "\n",
        "  model = tf.keras.models.load_model('model.h5')\n",
        "  pred = model.predict_classes(sample_data)\n",
        "\n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GrazXMiI0Nr4",
        "outputId": "1e4eec30-dcc7-4900-d025-0def59e9e4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "source": [
        "test_pefile(\"putty.exe\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-fd0bf5dddfde>:19: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0]]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}