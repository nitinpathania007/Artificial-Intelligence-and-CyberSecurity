{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm_training_model_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiwha1S2mZrL",
        "colab_type": "text"
      },
      "source": [
        "This was done in google collabration after getting sevaral errors in AWS sagemaker. I finally ran the whole code. I was able to use google drive as disk. Training was done on 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWOnMnyjzcCk",
        "colab_type": "code",
        "outputId": "fc179ec2-d07b-45b9-d12a-76d7d2fdf97e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!cp -r ember-master/* .\n",
        "!rm -r ember-master\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-12 15:03:44--  https://github.com/endgameinc/ember/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/endgameinc/ember/zip/master [following]\n",
            "--2020-04-12 15:03:45--  https://codeload.github.com/endgameinc/ember/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [      <=>           ]  11.22M  4.95MB/s    in 2.3s    \n",
            "\n",
            "2020-04-12 15:03:48 (4.95 MB/s) - ‘master.zip’ saved [11769324]\n",
            "\n",
            "Archive:  master.zip\n",
            "f9a018632ba108b4e25c33d6c3e2e7a7c4487f58\n",
            "   creating: ember-master/\n",
            "  inflating: ember-master/LICENSE.txt  \n",
            "  inflating: ember-master/README.md  \n",
            "   creating: ember-master/ember/\n",
            "  inflating: ember-master/ember/__init__.py  \n",
            "  inflating: ember-master/ember/features.py  \n",
            "   creating: ember-master/licenses/\n",
            "  inflating: ember-master/licenses/AGPL-LICENSE-3.0.txt  \n",
            "  inflating: ember-master/licenses/MIT-LICENSE.txt  \n",
            "   creating: ember-master/malconv/\n",
            "  inflating: ember-master/malconv/README.md  \n",
            "  inflating: ember-master/malconv/malconv.h5  \n",
            "  inflating: ember-master/malconv/malconv.py  \n",
            "  inflating: ember-master/malconv/multi_gpu.py  \n",
            "  inflating: ember-master/requirements.txt  \n",
            "  inflating: ember-master/requirements_conda.txt  \n",
            "  inflating: ember-master/requirements_notebook.txt  \n",
            "   creating: ember-master/resources/\n",
            "  inflating: ember-master/resources/ember-notebook.ipynb  \n",
            "  inflating: ember-master/resources/ember2018-notebook.ipynb  \n",
            "  inflating: ember-master/resources/logo.png  \n",
            "   creating: ember-master/scripts/\n",
            "  inflating: ember-master/scripts/classify_binaries.py  \n",
            "  inflating: ember-master/scripts/train_ember.py  \n",
            "  inflating: ember-master/setup.py   \n",
            "Collecting lief>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/38/e6bf942cf2ee073bf81fa3324bca35409175312b7b72d71919c8fc8e547b/lief-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.31.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (0.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->-r requirements.txt (line 4)) (1.12.0)\n",
            "Installing collected packages: lief\n",
            "Successfully installed lief-0.10.1\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ember.egg-info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing requirements to ember.egg-info/requires.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ember\n",
            "copying ember/__init__.py -> build/lib/ember\n",
            "copying ember/features.py -> build/lib/ember\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/ember-0.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.6.egg\n",
            "Copying ember-0.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding ember 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/ember-0.1.0-py3.6.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lightgbm==2.2.3\n",
            "Best match: lightgbm 2.2.3\n",
            "Adding lightgbm 2.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pandas==1.0.3\n",
            "Best match: pandas 1.0.3\n",
            "Adding pandas 1.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tqdm==4.38.0\n",
            "Best match: tqdm 4.38.0\n",
            "Adding tqdm 4.38.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lief==0.10.1\n",
            "Best match: lief 0.10.1\n",
            "Adding lief 0.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIvWxyq45YQB",
        "colab_type": "code",
        "outputId": "ea2ff400-fcbc-48ba-c538-2be5c7637ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wguk7hcNyzf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  feature_size=2381\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  #Model architecture\n",
        "  from tensorflow.keras import layers\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1500, activation='relu',activity_regularizer=tf.keras.regularizers.l1(l=0.01)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibCKQVYZy8CQ",
        "colab_type": "code",
        "outputId": "507e9ff3-9647-4c00-e2db-3914675493f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "model = make_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 1, 2381)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 1500)           3573000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1500)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 1)              1501      \n",
            "=================================================================\n",
            "Total params: 3,574,501\n",
            "Trainable params: 3,574,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO-a-4Ft0gfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ember_2017_2\n",
        "!cp -r drive/My\\ Drive/midtermdata/* ember_2017_2/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFhGb3WzA3_",
        "colab_type": "code",
        "outputId": "941123ed-0b0a-4842-af8d-ba14055dd495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import ember\n",
        "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"ember_2017_2/\")\n",
        "metadata_dataframe = ember.read_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_OZJ4AZCjXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelrows = (y_train != -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhZGpgH2Co68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEDXTfZHGhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iINPTg2JIiCs",
        "colab_type": "code",
        "outputId": "9c535c6d-2c7f-4d62-d451-fb68e1df18d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNKnqF_LFxvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('X_train.h5', 'w')\n",
        "h5f.create_dataset('X_train', data=X_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-7MKh2nHu3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('y_train.h5', 'w')\n",
        "h5f.create_dataset('y_train', data=y_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_DOPo_fs79",
        "colab_type": "code",
        "outputId": "6d940a7a-e736-40ef-c5d2-1d48e03690d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!rm drive/My\\ Drive/data/ember_2017_2/X_train.dat\n",
        "!rm drive/My\\ Drive/data/ember_2017_2/y_train.dat\n",
        "!cp X_train.h5 drive/My\\ Drive/data/ember_2017_2/\n",
        "!cp y_train.h5 drive/My\\ Drive/data/ember_2017_2/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'drive/My Drive/data/ember_2017_2/X_train.dat': No such file or directory\n",
            "rm: cannot remove 'drive/My Drive/data/ember_2017_2/y_train.dat': No such file or directory\n",
            "cp: cannot create regular file 'drive/My Drive/data/ember_2017_2/': Not a directory\n",
            "cp: cannot create regular file 'drive/My Drive/data/ember_2017_2/': Not a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdhUB2677b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXEUvwh78uFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(0,600000,100000):\n",
        "  mms.partial_fit(X_train[x:x+100000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvW0HlvkJToE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"drive/My Drive/midtermdata/mms_scaler\",\"wb\") as f:\n",
        "  import pickle\n",
        "  pickle.dump(mms,f)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HJvH9L9GyC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('X_train.h5','r')\n",
        "X_train = h5f['X_train'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pykFqHT3G-jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = mms.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbc15oKHz-De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train = np.reshape(X_train,(-1,1,2381))\n",
        "y_train = np.reshape(y_train,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et14cXjp2fuF",
        "colab_type": "code",
        "outputId": "09e39c3f-f796-4512-d655-8f048b839029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "pkl_base=\"drive/My Drive/data/pickles/\"\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=256,\n",
        "                epochs=1,\n",
        "                  validation_data =((X_train[600000-120000:600000],y_train[600000-120000:600000]))\n",
        "                  )\n",
        "model_name=\"my_model_test-tpu3.h5\"\n",
        "model_weights=\"weights_test-tpu3.h5\"\n",
        "model.save(pkl_base+model_name)\n",
        "model.save_weights(pkl_base+model_weights)\n",
        "print(model_name,model_weights,\" are saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 600000 samples, validate on 120000 samples\n",
            "600000/600000 [==============================] - 246s 411us/sample - loss: 14.4781 - accuracy: 0.9151 - auc_1: 0.9432 - precision_1: 0.9125 - val_loss: 16.9198 - val_accuracy: 0.9670 - val_auc_1: 0.9708 - val_precision_1: 0.9705\n",
            "my_model_test-tpu3.h5 weights_test-tpu3.h5  are saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ULVcZVqSFsL",
        "colab_type": "code",
        "outputId": "b25818d3-272c-479f-c637-d59d554cc129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "pkl_base=\"drive/My Drive/data/pickles/\"\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=128,\n",
        "                epochs=30,\n",
        "                  validation_split=.2,\n",
        "                  callbacks=[callback]\n",
        "                  )\n",
        "model_name=\"my_model_test6.h5\"\n",
        "model_weights=\"weights_test6.h5\"\n",
        "model.save(pkl_base+model_name)\n",
        "model.save_weights(pkl_base+model_weights)\n",
        "print(model_name,model_weights,\" are saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 10.9244 - accuracy: 0.7073 - auc_3: 0.8197 - precision_3: 0.6944 - val_loss: 13.1204 - val_accuracy: 0.7889 - val_auc_3: 0.9130 - val_precision_3: 0.7248\n",
            "Epoch 2/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 7.7330 - accuracy: 0.7073 - auc_3: 0.8212 - precision_3: 0.7000 - val_loss: 29.0429 - val_accuracy: 0.7804 - val_auc_3: 0.8916 - val_precision_3: 0.7182\n",
            "Epoch 3/30\n",
            "480000/480000 [==============================] - 247s 515us/sample - loss: 6.1617 - accuracy: 0.7160 - auc_3: 0.8244 - precision_3: 0.8438 - val_loss: 11.4132 - val_accuracy: 0.8012 - val_auc_3: 0.9190 - val_precision_3: 0.9902\n",
            "Epoch 4/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 4.6572 - accuracy: 0.7040 - auc_3: 0.8123 - precision_3: 0.8465 - val_loss: 12.6347 - val_accuracy: 0.7628 - val_auc_3: 0.9021 - val_precision_3: 0.9925\n",
            "Epoch 5/30\n",
            "480000/480000 [==============================] - 246s 512us/sample - loss: 8.2998 - accuracy: 0.7103 - auc_3: 0.8216 - precision_3: 0.7619 - val_loss: 10.3378 - val_accuracy: 0.8109 - val_auc_3: 0.9035 - val_precision_3: 0.9921\n",
            "Epoch 6/30\n",
            "480000/480000 [==============================] - 250s 521us/sample - loss: 5.1247 - accuracy: 0.7075 - auc_3: 0.8149 - precision_3: 0.8464 - val_loss: 11.0532 - val_accuracy: 0.7952 - val_auc_3: 0.8941 - val_precision_3: 0.9932\n",
            "Epoch 7/30\n",
            "480000/480000 [==============================] - 247s 515us/sample - loss: 6.1394 - accuracy: 0.7094 - auc_3: 0.8135 - precision_3: 0.9123 - val_loss: 14.2248 - val_accuracy: 0.8167 - val_auc_3: 0.9254 - val_precision_3: 0.9932\n",
            "Epoch 8/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 7.2303 - accuracy: 0.7064 - auc_3: 0.8194 - precision_3: 0.7033 - val_loss: 21.4480 - val_accuracy: 0.7898 - val_auc_3: 0.8876 - val_precision_3: 0.9899\n",
            "Epoch 9/30\n",
            "480000/480000 [==============================] - 247s 514us/sample - loss: 5.7969 - accuracy: 0.7017 - auc_3: 0.8145 - precision_3: 0.6636 - val_loss: 21.1786 - val_accuracy: 0.7962 - val_auc_3: 0.9155 - val_precision_3: 0.9927\n",
            "Epoch 10/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 6.5409 - accuracy: 0.7048 - auc_3: 0.8152 - precision_3: 0.6462 - val_loss: 15.3661 - val_accuracy: 0.8140 - val_auc_3: 0.9054 - val_precision_3: 0.7490\n",
            "Epoch 11/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 5.3258 - accuracy: 0.6948 - auc_3: 0.8083 - precision_3: 0.7243 - val_loss: 28.5340 - val_accuracy: 0.7729 - val_auc_3: 0.8594 - val_precision_3: 0.9932\n",
            "Epoch 12/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 5.0730 - accuracy: 0.7084 - auc_3: 0.8067 - precision_3: 0.9488 - val_loss: 8.9624 - val_accuracy: 0.8303 - val_auc_3: 0.9166 - val_precision_3: 0.9928\n",
            "Epoch 13/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 4.6000 - accuracy: 0.7003 - auc_3: 0.7990 - precision_3: 0.9360 - val_loss: 22.5536 - val_accuracy: 0.8035 - val_auc_3: 0.9166 - val_precision_3: 0.9923\n",
            "Epoch 14/30\n",
            "480000/480000 [==============================] - 247s 514us/sample - loss: 3.9132 - accuracy: 0.6951 - auc_3: 0.7892 - precision_3: 0.9536 - val_loss: 20.2699 - val_accuracy: 0.7828 - val_auc_3: 0.8974 - val_precision_3: 0.9940\n",
            "Epoch 15/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 5.4533 - accuracy: 0.6920 - auc_3: 0.7892 - precision_3: 0.9263 - val_loss: 16.6709 - val_accuracy: 0.7924 - val_auc_3: 0.9126 - val_precision_3: 0.9900\n",
            "Epoch 16/30\n",
            "480000/480000 [==============================] - 248s 518us/sample - loss: 6.9528 - accuracy: 0.7121 - auc_3: 0.8069 - precision_3: 0.9625 - val_loss: 9.3146 - val_accuracy: 0.8374 - val_auc_3: 0.8952 - val_precision_3: 0.9934\n",
            "Epoch 17/30\n",
            "480000/480000 [==============================] - 247s 515us/sample - loss: 4.2632 - accuracy: 0.7026 - auc_3: 0.7977 - precision_3: 0.9653 - val_loss: 14.6118 - val_accuracy: 0.8106 - val_auc_3: 0.9181 - val_precision_3: 0.9955\n",
            "Epoch 18/30\n",
            "480000/480000 [==============================] - 246s 512us/sample - loss: 8.6937 - accuracy: 0.6971 - auc_3: 0.7917 - precision_3: 0.9563 - val_loss: 16.8546 - val_accuracy: 0.7979 - val_auc_3: 0.9144 - val_precision_3: 0.9887\n",
            "Epoch 19/30\n",
            "480000/480000 [==============================] - 246s 513us/sample - loss: 6.4056 - accuracy: 0.6886 - auc_3: 0.8002 - precision_3: 0.7027 - val_loss: 9.9628 - val_accuracy: 0.8167 - val_auc_3: 0.9087 - val_precision_3: 0.7513\n",
            "Epoch 20/30\n",
            "480000/480000 [==============================] - 248s 516us/sample - loss: 6.4125 - accuracy: 0.6917 - auc_3: 0.8006 - precision_3: 0.7397 - val_loss: 8.5120 - val_accuracy: 0.8280 - val_auc_3: 0.9259 - val_precision_3: 0.9934\n",
            "Epoch 21/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 4.2397 - accuracy: 0.6903 - auc_3: 0.7862 - precision_3: 0.9642 - val_loss: 11.0104 - val_accuracy: 0.7642 - val_auc_3: 0.8966 - val_precision_3: 0.9940\n",
            "Epoch 22/30\n",
            "480000/480000 [==============================] - 247s 514us/sample - loss: 4.9618 - accuracy: 0.6811 - auc_3: 0.7838 - precision_3: 0.8239 - val_loss: 9.7756 - val_accuracy: 0.8006 - val_auc_3: 0.9163 - val_precision_3: 0.9946\n",
            "Epoch 23/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 4.2787 - accuracy: 0.6854 - auc_3: 0.7828 - precision_3: 0.9045 - val_loss: 10.1198 - val_accuracy: 0.7700 - val_auc_3: 0.8979 - val_precision_3: 0.9922\n",
            "Epoch 24/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 4.6620 - accuracy: 0.6865 - auc_3: 0.7831 - precision_3: 0.9430 - val_loss: 7.6998 - val_accuracy: 0.7506 - val_auc_3: 0.8925 - val_precision_3: 0.9935\n",
            "Epoch 25/30\n",
            "480000/480000 [==============================] - 249s 518us/sample - loss: 5.3849 - accuracy: 0.6820 - auc_3: 0.7792 - precision_3: 0.8999 - val_loss: 9.6819 - val_accuracy: 0.7587 - val_auc_3: 0.8858 - val_precision_3: 0.9944\n",
            "Epoch 26/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 4.1110 - accuracy: 0.6824 - auc_3: 0.7760 - precision_3: 0.9452 - val_loss: 11.0504 - val_accuracy: 0.7758 - val_auc_3: 0.8967 - val_precision_3: 0.9947\n",
            "Epoch 27/30\n",
            "480000/480000 [==============================] - 248s 516us/sample - loss: 3.9746 - accuracy: 0.6777 - auc_3: 0.7652 - precision_3: 0.9650 - val_loss: 21.4000 - val_accuracy: 0.7736 - val_auc_3: 0.8876 - val_precision_3: 0.9930\n",
            "Epoch 28/30\n",
            "480000/480000 [==============================] - 248s 517us/sample - loss: 5.3689 - accuracy: 0.6849 - auc_3: 0.7781 - precision_3: 0.9492 - val_loss: 9.7641 - val_accuracy: 0.8066 - val_auc_3: 0.9133 - val_precision_3: 0.9949\n",
            "Epoch 29/30\n",
            "480000/480000 [==============================] - 247s 515us/sample - loss: 6.1464 - accuracy: 0.6880 - auc_3: 0.7784 - precision_3: 0.9660 - val_loss: 10.9887 - val_accuracy: 0.8037 - val_auc_3: 0.9128 - val_precision_3: 0.9948\n",
            "Epoch 30/30\n",
            "480000/480000 [==============================] - 247s 515us/sample - loss: 3.9302 - accuracy: 0.6855 - auc_3: 0.7743 - precision_3: 0.9644 - val_loss: 11.9121 - val_accuracy: 0.7834 - val_auc_3: 0.8936 - val_precision_3: 0.9949\n",
            "my_model_test-tpu6.h5 weights_test-tpu6.h5  are saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hlw5HLqquKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}