
Youtube Video Link
https://www.youtube.com/watch?v=XSpcuAhaejY


We are going to create a REST API for doing breast cancer detection from histopathology images which is publically available imageset on kaggle, which later can be integrated into a full web application that doctors can use for doing diagnostics.. We would be using image classification algorithms in AWS sagemaker that integrate seamlessly with the REST API. 
Now, I'll introduce you to the AWS SageMaker fundamental concepts so you have a better understanding of the platform before I tell you how to build a REST API for breast cancer detection. So, what is AWS SageMaker? It is a fully managed machine learning service. With SageMaker, everyday data scientists and developers, just like us, can quickly and easily build, train, and deploy machine learning models into production‑ready hosted environments. 
For building, AWS SageMaker provides notebook instances which come with Jupyter preinstalled, so you can start creating your notebooks right away. It also comes with pre‑built notebooks, which contain several examples that can help you with your initial steps in the platform. SageMaker also comes with built‑in, high‑performance algorithms that have been optimized for faster running speeds, and you can use them from the very first moment. Also, if you prefer, you can create your own algorithms. So, what's the difference between using built‑in algorithms and using your own algorithms? Well, using built‑in algorithms has many advantages. You have several algorithms that you can use for a variety of problem types. They are ready to be used and optimized for production workloads; however, using your own algorithms gives you the flexibility to use almost any algorithm code in implementation language in any dependent libraries and frameworks. And one important thing to mention is that you can use TensorFlow and Apache MXNet Docker containers that are already provided by AWS SageMaker. One important thing to take into account is that AWS SageMaker offers several built‑in algorithms, and the problem you want to solve influences the algorithm you choose. We want  to classify images into categories, as we're going to do for our Breast Cancer Detection API, you can use the Image Classification algorithm.

For training, AWS SageMaker helps you with the hyperparameter optimization process. You don't have to waste your time anymore by doing random trial and error tuning. AWS SageMaker takes care of hyperparameter optimization for you. For deploying, AWS SageMaker helps you with the provision of endpoints so external applications can easily get predictions from your trained model. AWS SageMaker provides notebook instances where you can start building your machine learning models. A notebook instance, put in simple words, is a fully managed machine learning compute instance running the Jupyter Notebook app, including related resources. So, what are those related resources I'm talking about? They include Anaconda packages for data science, TensorFlow and Apache MXNet, storage volume, which you can use to locally process a large dataset or to temporarily store other data to work with, example Jupyter Notebooks that contain several use cases you can take a look at to get started with the AWS SageMaker platform. And, if you're wondering about what tasks you can perform on a notebook instance, you can prepare and process input data for your models, write code to train models, deploy models to AWS SageMaker hosting, and test or validate your models.
Let's take a look now to Building a Model in AWS SageMaker for Breast Cancer Detection Using a Built‑in Algorithm. For this case, the most appropriate built‑in algorithm to use will be the image classification algorithm. It is a supervised learning algorithm which takes an image as an input and classifies it into one of multiple categories using a convolutional neural network. 

One important thing to notice is that you can configure the training mode for this algorithm, which falls into two categories, full training and transfer learning. In full training mode, the neural network is initialized with random weights and trained from scratch, so it needs a lot of input images. In transfer learning mode, the neural network is initialized with pre‑trained weights, and just the top fully connected layer is initialized with random weights, so it needs a smaller number of input images. When training, the whole network is fine‑tuned with user images. 

Another important aspect of the image classification algorithm is that it accepts two formats for input images. The first one, and also the recommended one, is the Apache MXNet RecordIO format. The second one is raw images in JPEG or PNG format. 

So, what's the difference between using RecordIO and raw images? If you use RecordIO, you can take advantage of AWS SageMaker Pipe mode. In Pipe mode, your training job streams data directly from S3, which means faster start times, better throughput, and reduced storage volume usage. On the other side, using raw images means AWS SageMaker will use File mode by default. In file mode, your training job loads all your training data from S3 to the training instance volumes first, which means slower start times, lower throughput, and higher storage volume usage. Loading raw images can work on Pipe mode too; however, you have to provide an additional augmented manifest file. 

Moving on the with image classification algorithm configuration, it has several hyperparameters that can be adjusted for a better performance, which, at the end of the day, means having a more accurate model for doing breast cancer detection and saving more lives. 

The definition of hyperparameter, it is a parameter that set before the learning process begins. These parameters are tunable, and can directly affect how well a model trains. 
The image classification algorithm has two required hyperparameters. One is the number of classes, which for the breast cancer detection problem we want to solve will just be two, meaning cancer detected or no cancer detected. The other one is the number of training samples or the number of images we are going to use for training the model. 
SageMaker has two available APIs for building models using built‑in algorithms. The first one is a low‑level AWS SDK for Python, and the second one is a high‑level SageMaker Python library.



The first step will be creating a new Jupyter notebook. Next, we have built the process for obtaining the histopathology images that will be used as input for the image classification algorithm. Then, we are going to explore the images so we have a sense of what it is we are dealing with. And finally, we are going to convert the images to the RecordIO format because that is the most performant solution and then upload to s3.  

Do your own

Now we will be building a model in AWS SageMaker for breast cancer detection using Tensorflow. This means creating a custom algorithm of our own instead of using the built‑in image classification algorithm. By the way, the latest version of Tensorflow supported by the SageMaker Python SDK is 1.12.0. Please remember, it's recommended to use the latest supported version of Tensorflow, because that's where AWS focuses most of its development efforts. 

The process we're going to follow for building a Tensorflow model in SageMaker is the following. First, we're going to transform the input images to the TFRecord format, which, like the RecordIO format we have discussed before, is more efficient for training. Then we're going to prepare a training  script. And finally, we're going to build a model using the Tensorflow estimator provided by the SageMaker Python SDK. 

SageMaker gives your script access to useful properties about the training environment through environment variables. Some of the available environment variables are SM_MODEL_DIR, which is a string that represents the local path where the training job can write the model artifact to. After training, artifacts in this directory are uploaded to S3 for model hosting. SM_NUM_GPUS, this is an integer representing the the number of GPUs available to the host. SM_OUTPUT_DATA_DIR, this is a string that represents the path to the directory to write output artifacts to. Output artifacts might include checkpoints, graphs, and other files to save, but do not include model artifacts. These artifacts are compressed and uploaded to an S3 bucket with the same prefix as the model artifact. SM_CHANNEL, it is a string that represents the path to the directory that contains the input data for the specified channel. For example, if you specify two input channels in a Tensorflow estimator's feed call named train and test, the environment variables SM_CHANNEL_TRAIN and SM_CHANNEL_TEST are set.



Lets see how to build a model using Apache MXNet. The latest version of Apache MXNet supported by the SageMaker Python SDK is 1.3.0. And, as I've mentioned before for TensorFlow, please remember it's recommended to use the latest supported version of MXNet because that's where AWS focuses most of its development efforts. 

The process we're going to follow for building an MXNet model in SageMaker is very similar to the process we have used for TensorFlow. First, we're going to transfer the input images to the RecordIO format we have discussed before because it's more efficient for training. Then, we're going to prepare a training script. And finally, we're going to build a model using the MXNet Estimator provided by the SageMaker Python SDK. 

SageMaker gives your MXNet script access to useful properties about the training environment through environment variables. Just to remember, these are some of the available environment variables, and they are basically the same as in the TensorFlow case, SM_MODEL_DIR, SM_NUM_GPUS, SM_OUTPUT_DATA_DIR, and SM_CHANNEL.



Let's move on now and talk about automatic hyperparameter optimization, HPO, in SageMaker. A problem we all have to face when building and training machine learning models is that selecting the right hyperparameter values can be difficult. The right answer depends on the algorithm and the data. 

automatic hyperparameter optimization help us find the best version of a model by running many training jobs. For that, it uses the algorithm and ranges of hyperparameters that you specify, and it chooses the hyperparameter values that result in a model that performs the best as measured by a metric that you choose. At the end of the day, hyperparameter optimization is a supervised learning problem. Given a set of input features, the hyperparameters, hyperparameter tuning optimizes a model for the metric that you choose. 

We can define objective metrics for hyperparameter optimization. When using built‑in algorithms, you don't need to define metrics. They are sent automatically to hyperparameter tuning; however, you do need to choose the objective metric for the tuning job. When using custom algorithms, your algorithm has to emit at least one metric by writing evaluation data to stderr or stdout. 
You can define up to 20 metrics for the tuning job to monitor. You choose one of those metrics to be the objective metric. You define metrics by specifying a name and a regular expression for parsing training logs. By the way, the built‑in image classification algorithm has many tunable hyperparameters, the mini_batch_size, the learning_rate, the optimizer, and other hyperparameters related with the optimizer itself, beta_1, beta_2, eps, gamma, momentum, and weight_decay.


Let's see now how we can deploy and test machine learning models in AWS SageMaker hosting services. Deploying a model using AWS SageMaker hosting service is a three‑step process. First, you have to create a model in AWS SageMaker. By creating a model, you tell SageMaker where it can find the model component, which include the S3 path where the model artifacts are stored. The model artifacts are the outputs we get when training a model. And also, the Docker registry path for the image that will be used for making predictions. Then you have to create an endpoint configuration for an HTTPS endpoint. Here is where you specify the name of the model you want to deploy and the number and type of machine learning compute instances that you want a AWS SageMaker to launch to host them all. Finally, you have to create an HTTPS endpoint. For that, you provide an endpoint configuration that was previously created. So, AWS SageMaker launches the machine learning computer instances and deploys the model as specified in the configuration. Something important to notice here is that if you specify you want two or more instances for deploying a model, AWS SageMaker launches them in multiple Availability Zones, ensuring high availability. 

After a model is deployed in AWS SageMaker, to validate it, you can send sample requests and get inferences directly from a Jupyter Notebook.

On your own

Overview of Integrating Endpoints with AWS API Gateway and AWS Lambda
Now that we have deployed our models for breast cancer detection to AWS SageMaker hosting, let's discuss about how we could integrate them with AWS API Gateway and AWS Lambda so we have an internet‑facing REST API that can be invoked from external application. And if you're wondering about what is AWS API Gateway, it is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at scale. With a few clicks in the AWS console, you can create REST APIs that act as a front door for applications to access your back‑end services, such as code running on AWS Lambda. And that poses another question. What is AWS Lambda? It's a service that lets you run code without provisioning or managing servers for virtually any type of application or back‑end service, paying only for the compute time you consume, meaning you don't get charged when your code is not running. And also, it can be automatically triggered from other AWS services, such as AWS API Gateway. So, now that we have a general idea about AWS, API Gateway and AWS Lambda, let's think about the architecture we're going to use for integrating those services with AWS SageMaker so that at the end we have an internet‑facing REST API for doing breast cancer detection from histopathology images that can be invoked from external applications. The first component in this architecture is obviously the client application that wants to use the REST API for breast cancer detection. It could be a mobile, web, or desktop app. The second component will be an AWS API Gateway, which will expose the REST API that external client applications will interact with. AWS API Gateway should automatically trigger an AWS Lambda function, which will contain Python code for invoking an AWS SageMaker endpoint. The Python code in the Lambda function should be very similar to the code we have seen on the previous demos where we were testing our endpoints.

Integrating an AWS SageMaker Endpoint with AWS API Gateway and AWS Lambda
And, well, it's time to see this architecture in action now. So we're going to create a Lambda function for invoking a SageMaker endpoint. Then, we will create an API Gateway for calling the Lambda function. And finally, we're going to test the API Getaway with Postman, which will be the client application. Okay, so the first step of this demo will be creating a Lambda function that will invoke one of the endpoints we have created previously. I'll choose the first endpoint we have created, which corresponds to the model built based on the build‑in Image Classification algorithm. For creating the Lambda function, go to the AWS console and look for the Lambda service. Go to the Functions menu and click on Create function. On the Create function page, set the Author from scratch option, then provide a descriptive function name, such as predictBreastCancer. Choose Python 3.6 as the runtime. Next, we need to provide an IAM role, such that our new Lambda function has permissions to invoke SageMaker endpoints and to send logs to CloudWatch. For creating the role, click on the link to create a custom role. On the Create role page, choose Lambda as the service that will use the role and then click on Next: Permissions. Then, click on the Create policy button. That will open a new page for creating a policy. On the visual editor, choose SageMaker as service. Choose InvokeEndpoint as action. In Resources, choose All resources. Then, click on Add additional permissions. Choose CloudWatch Logs as service. Choose CreateLogGroup, CreateLogStream, and PutLogEvents as actions. In Resources, choose All resources. Finally, click on Review policy. On the Review policy page, give the policy a name, add a short description, and finally click on Create policy. Back on the Create role page, refresh the policy list and look for the policy we have just created. Select it and click on Next: Tags. I'll add no tags to the rows, so I'll click on Next: Review. On the Review page, give your role a name, add a short description, and finally click on Create role. Back on the Lambda Function Creation page. select Use an existing role, refresh the existing role list, and then choose the role we have created. Finally click on Create function. Once the Lambda function is created, a new page will be displayed where you can find a code editor for defining the logic. I'll paste the code here. First, I'll import some libraries that will be needed. Then you have to create an instance of the boto3 SageMaker runtime client so the Lambda function can interact with SageMaker. Next, a lambda_handler function is defined. This is the function that will get invoked from external applications. It receives two dictionaries, event and context. Inside the lambda_handler, I need to obtain the image that was sent from the external application that invoked the function. It will come Base64‑encoded, so I'm decoding it as well. Then you can provide a decoded image to the predict_breast_cancer function, which invokes the endpoint we have previously created in SageMaker, sending the image with a Content‑Type of application/x‑image. Then a result is obtained, and if you remember, it is an array, which contains the probabilities of the 0 and 1 classes for the corresponding image. Then you have to calculate the predicted_class, which is a class with a higher probability. If the predicted_class is 0, then no cancer was detected. Otherwise, cancer was detected. Finally, you have to save changes, clicking on the Save button. And that's it for creating the Lambda function. Now we can create an API Gateway that will allow us to define a RESTful service for triggering the Lambda function, meaning invoking the SageMaker endpoint. For that, go to the AWS console and look for the API Gateway service. Click on the Create API button. On the next page, choose REST as the protocol. Choose the New API option. Give your API a name, such as predictBreastCancerApi. Give it a short description and click on Create API. Then in the Actions menu, choose Create Resource. Give the resource a name, for example predict‑breast‑cancer, and click on Create Resource. Then on the Actions menu, choose Create Method and select POST. Next, choose Lambda Function as integration type and predictBreastCancer as the Lambda Function. Click on Save and then click on OK for adding a permission so that the API can call the predictBreastCancer Lambda function. Finally, we need to make some adjustments so the API can accept images. For that, click on the Settings menu of the API, then click on Add Binary Media type, write application/x‑image, and click on Save Changes. Then back to the POST method in the predict‑breast‑cancer resource, click on Integration Request. Go to the Mapping Templates section. Select the option when there are no templates defined for request body passed through, then click on Add mapping template, write application/x‑image as Content‑Type, and finally add the following to the mapping template. This basically means that when the API receives a request with a Content‑Type of application/x‑image, the request body will be copied to an image field that will be sent to the Lambda function. That's why the Lambda function expects this field for loading image data. Finally, click on Save. And, well, we can deploy the API now. For that, click on Actions, Deploy API. Select New Stage as deployment stage. Give the new stage a name, for example production, and click on Deploy. If you go now to Stages, production, predict‑breast‑cancer, you'll see the invoke URL of the API. Now that the API is created, we can call it from Postman and create a new request so that the request method is POST, the request URL points to the API Gateway we have just created, the request body is binary. I'll choose one of the histopathology images I have downloaded to my computer. A Content‑Type of application/x‑image is set and click on Send. As you can see, we're receiving a response of Cancer not detected, so our REST API is working as expected. And that's it. We have successfully created a REST API for doing breast cancer detection that can be called from any external application. I hope you're very proud of yourself because we have done a lot of work to get to this point. And if you want to create REST APIs for the custom TensorFlow or MXNet models, the process will be very similar.










Demo low level API
Configuring the Image Classification Algorithm Using the High-level SageMaker Python Library
We already have the images we are going to need as inputs for the breast cancer detection model we are going to build.I'm going to create a new Jupyter notebook and choose conda_mxnet_p36 as the kernel and then the notebook as breast‑cancer‑detection‑with‑image‑classification‑low‑level. Now that we have our notebook created, I'll just important some modules and functions I'm going to need later, including Boto 3, which is the Python client for AWS and the SageMaker Python library. Then I'll create some variables for configuring the hyperparameters of the built‑in image classification algorithm. First, we have the number of classes with a value of 2, because our images have to be classified between no cancer detected, 0, and cancer detected, 1. Then we have the number of training samples. Next, we have the number of layers for the underlying neural network. I'm choosing a value of 18, and by the way, this value can be any integer. l'll set the mini_batch_size for training to a value of 128. This is just how many images at the time will be provided to the model for training. After that, I'll define the input image_shape for the training data to be 3,50,50. That's because the histopathology images we're working with have a size of 50 x 50 pixels and 3 channels, red, green and blue. Next, I'm defining an image augmentation_type with a value of crop_color_transform. That means our training dataset will be augmented by randomly cropping, flipping, changing hues, saturation, and likeness, rotating, shearing, and changing the aspect ratio of the original images. By the way, the reason why I am doing image augmentation is because we have a very unbalanced dataset. So with image augmentation, I'm trying to mitigate that problem. Then you have to define the number of epochs. I'm using a value of 5 for this. And next, l'll set the learning rate to be 0.01. Finally, I'm going to enable transfer learning by setting the use_pretrained_model to 1. And that's it for configuring the hyperparameters. As you know, there are other, but I'll just leave them with their default values. Next, we have to define a unique job name that will be used when we train the model we are just configuring. For that. I'm just going to use a name with a prefix of breast‑cancer‑detection and append the current time stamp to it. Then I'm going to specify the input paths for the job. For that, I'll specify the S3 bucket I'm working with and that I have already created, which is nitinproject1. Then I'll define the prefix where the input files are stored, which is the location where we have uploaded the RecordIO files we have already generated. And it was breast‑cancer‑detection/input/recordio. Then I defined the full S3 paths for the train and test dataset. Next, we have to define the output path for the job, which is the S3 location where the results of training the model we are building will be stored. I'll use an output_prefix of breast‑cancer‑detection/output. The following step Is configuring the training instances that will be used when the model we are building is trained. For that, we have to define how many instances we are going to use for training. I'll just use one instance for this case. If you choose a value higher than 1, distributed training is enabled. Then you have to define the instance type. I'm choosing ml.p2.xlarge because it's enough for what we are doing. If you look at this page, you can see it has 4 vCPUs, 1 GPU, 61 GB of memory, and 12 GB of GPU memory. I've chosen a GPU instance because that's a more performant solution when working with images. Finally, l'll set a storage volume size of 50 GB. One important thing I  want to mention right now is that your account may not have the permissions for creating enough ml.p2.xlarge instances. And if that's the case, what will happen is that when you try to train the model, you'll get an error because you don't have the permissions for creating the needed instances. The solution for that is pretty simple though. You'll just need to request a limit increase for ml.p2.xlarge instances to AWS support. Next, I'll get the SageMaker execution role, which is the IAM role we have selected when creating the notebook instance. For that, I run the get_execution_role function that SageMaker already provides us and that I have imported at the beginning. Then I'll obtain the URI of the training image that will be used when training the model. The training image is just a Docker image that contains all the necessary code, libraries, and frameworks that will be used while training. Obtaining the URI is very simple. You have just to call the get_image_uri that SageMaker provides and pass it the region you are working on and the name of the repo where the image is stored. For this case, the repo name is image‑classification. Now I'm going to configure the train_timeout in seconds, after which, Amazon SageMaker terminates the job, regardless of its current status. I am going to use this value, which is equivalent to 100 hours. Finally, we have to put it all together, creating a dictionary that the low‑level AWS SDK for Python will understand for creating and training the model. First, we have to provide it a training job name. Then in the AlgorithmSpecification section, we have to provide the training image URI and then set the TrainingInputMode to Pipe. That's because we are using RecordIO files as input, and we can benefit from pipe mode because, as we have already seen before, it's more performant than file mode. Then we have to provide the RoleArn. Next, in the ResoureConfig section, we have to provide an InstanceCount, InstanceType, and VolumeSizeInGB we have already defined. Then in the InputDataConfig section, we have to define the input channels for the training job that will be created when training the model. Those channels are the train and validation channels. For each channel, we have to define the ChannelName, the S3DataType to be S3Prefix , the S3Uri, the S3DataDistributionType to be FullyReplicated. Currently, the algorithm only supports the fully replicated model where data is copied onto each machine when distributed training is executed. The ContentType, which is application/x‑recordio for our use case, and the CompressionType, which is none because our input files are not compressed. Next, in the OutputDataConfig section, theS3OutputPath has to be provided. And in the HyperParameters section, we have to provide all the hyperparameters we have already defined above. And last but not least, in the StoppingCondition section, I'm passing the train_timeout variable. to the MaxRuntimeInSeconds property. And that's it for configuring the built‑in Image Classification algorithm using the low‑level AWS SDK for Python. 

Configuring the Image Classification Algorithm Using the High-level SageMaker Python Library
The first steps for configuring the Image Classification algorithm using the high‑level SageMaker Python library are exactly the same as on the previous demo where we used the low‑level AWS SDK for Python. First, I'll import the libraries that we are going to need. Then, I'm going to create some variables for configuring hyperparameters, create a unique job name, specify the input and output paths for the job, configure the training instances, get the execution role, the training image URI for image classification, and set the train timeout. Now, here comes the interesting part. Instead of creating that big dictionary we had created in the previous notebook, which contained all the specification for training the model, we're going to create a SageMaker Estimator. For that, I'm going to obtain the sagemaker‑session first, then I'm going to create Estimator itself using the sagemaker.estimator class and pass in to the constructor the training_image, the execution role, the train_instance_count, the train_instance_type, the train_volume_size, the train_max_run, which basically is the train timeout, the output_path, and the sagemaker_session. After the Estimator is created, we can set the hyperparameters for it, calling the set_hyperparameters method and passing all the hyperparameters we have configured above. And that's it for configuring the built‑in Image Classification algorithm using the high‑level SageMaker Python library.. 

















Demo
I'm going to create a new Jupyter Notebook. I'll choose conda_tensorflow_p36 as the kernel and name the notebook as breast‑cancer‑detection‑with‑tensorflow. First, I'll import the libraries that we are going to need, which obviously include TensorFlow. Then, before creating the model with TensorFlow, we need to convert the histopathology images to the TFRecord format, which is similar in conception to the RecordIO format, but it's more specific to TensorFlow. I'm doing this conversion because training with TFRecord files is more performant. So, I'm going to obtain all the image paths and shuffle them by executing the following Python comments. We can take a quick look to the first 10 image paths, then I'm going to obtain all image labels executing this code, which basically returns a list with a subdirectory on which each image is stored, which turns out to be the label, 0 or 1. We can take a quick look to the first 10 image labels as well. Then I'm going to load all the images as a NumPy array named dataset. First, I'm defining the array's shape. After that, I'm using a loop for loading each image using the load_img function we have imported at the beginning from the Keras image processing module, resizing each image to make sure all the images have the same size, converting each image to a NumPy array, using the image.array function from the Keras image pre‑processsing module. By the way, you can see I'm passing a channels_last parameter. That means each image gets loaded as a 50 x 50 x 3 array instead of 3 x 50 x 50. That's because TensorFlow, by default, works with this convention of having the number of channels as the last dimension and not the first one. Next, I am adding the image that was converted to a NumPy array to the resulting dataset. And finally, printing an informative message just for knowing how many images have been converted at a given time. Once all the images have been loaded into the dataset, I'm going to split it in train and test datasets. For that, I'm using a train_test_split function from scikit‑learn, which receives the dataset, the image_labels, the test_size with a value off 0.3, so we have a split of 30% for testing and 70% for training, and the random state, which is just a number that serves a seat for the random number generator that's used internally by the function. Next, we have to convert the training and test datasets to the TFRecord format. For that, I'm using this function, which receives a NumPy array of images, the image's labels, the number of examples in the NumPy array, the name of their resulting TFRecord file, and the directory where it will be stored. I won't get into the details of this function, but it's important to notice that it uses the TFRecordWriter class from TensorFlow for creating the TFRecord files, and that for each file, the following information is included, its height and width, its depth, which is the number of channels, its label, and the row image itself. So for converting the train dataset to TFRecord, I'm going to call the convert_to_tfrecord function with X_train, y_train, the length of y_train, which is the number of examples, and I'm going to indicate that the resulting file should be named images_train and stored in the current working directory. For converting the test dataset, I'm doing something similar for generating a file called images_test. After the conversion is done, If you go to the Jupyter main page, you will see two new files. Finally, I'll just upload the TFRecords records files to S3 using the AWS CLI to the sagemaker‑data‑jv bucket and the breast‑cancer‑detection/input TFRecord prefix.

Configuring a Tensorflow Estimator Using the High-level SageMaker Python Library
On this new demo, we're going to see how to prepare a training Python script and, finally, how to configure a TensorFlow estimator using the high‑level SageMaker Python library. By the way, it's worth to mention that we can't use a low‑level AWS SDK for Python on this case. Now that we have converted the images to the TFRecord format and have loaded them to S3, we can prepare the training script. I'm going to guide you through the process of creating the script. However, I'm not going to go into every little detail of TensorFlow. The most important thing for now is that you understand how you can adapt your own TensorFlow scripts for using them in SageMaker, and obviously your scripts don't need to be exactly the same as the one I'll be creating now. Also, if you want to get more details about using TensorFlow in SageMaker, you can read this link from the SageMaker Python SDK documentation. Another good learning resource is the SageMaker example notebook's GitHub page, where you can find a lot of examples for several use cases. And, by the way, the demos on this course are inspired on several of those examples. And, well, a typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves it so it can be deployed for inference later. Let's start creating the training script. For that, go to the Jupyter home page and click on New, Text File. That will open a new window with the file. Make sure to rename it to tensorflowScript.py. First, I'll import some libraries the script is going to need, including NumPy and TensorFlow, and others like argparse for parsing command‑line arguments. Next, I'm setting the TensorFlow logging verbosity to INFO so that training logs get displayed accordingly. Also, I'm going to paste some constants that I'll use later. Now I'll create a private function for parsing command‑line arguments that the script will accept. First, I'll get the model‑dir, which is the location where model data, checkpoint data, and TensorBoard checkpoints shall be saved during training. Then, I'll get the sm‑model‑dir, which is a string that represents the local path where the training job can write the model artifacts to. After training, artifacts in this directory are uploaded to S3 for model hosting. This is different than the model‑dir argument, which is an S3 location. As you can see, the default value for this variable will be obtained from the sm‑model‑dir environment variable that SageMaker provides. Next, I get the train and test variables. Both variables represent the path to the directory that contains the input data for the specified channel. The default value for these variables is obtained from environment variables as well, SM_CHANNEL_TRAIN and the SM_CHANNEL_TEST. Then, I get the list of training hosts and the current host for training. This is important because if we execute training on a distributed environment, meaning there will be many training hosts, we need a way to know the list of hosts and the current host where training is happening. The default values for these are also obtained from environment variables, SM_HOSTS and SM_CURRENT_HOST. Finally, I obtained some hyperparameters that the model will need, the num‑classes with a default value of 2, the mini‑batch‑size with a default value of 100, the max‑steps with a default value of 100, and the learning‑rate with a default value of 0.1. As you can see, it isn't something very difficult. The only important thing to remember is that the training script can accept any values you want, and that SageMaker provides useful environment variables that can be used anywhere in this script. Now that we have the ArgumentParser function, let's call it from a main _____, which is the entry point of any Python script. The next function we are going to need is one that reads and decodes the TFRecord files we have previously generated for our train and test datasets. For that, the reader and decode function receives a filename_queue and uses the TFRecordReader class for parsing each example contained in the file and loading the image itself and its label. Notice that each image is being normalized as well, dividing the pixel values by 255 so that all the values are between 0 and 1. This is a very common practice when training machine learning algorithms that work with images. Now I'll create another function named input_fn, which will receive a directory, a TFRecord filename, and the mini_batch_size so that it calls the read_and_decode function and produces batches of images with a size determined by mini_batch_size that will serve as input for the model we are going to build and train. Next, I'll create two other functions named train_input function and eval_input function. They are simple wrappers around the input_function for loading train and test data, respectively. You can see the train_input function expects to load a file named images_train.tfrecords, and the eval_input function expects to load a file named images_test.tfrecords. Now that I have train_input function and eval_input function, I'll use those functions to create train_spec and eval_spec objects in the main section of the script. The train_spec receives the train_input function called with the train directory and the mini_batch_size. It also receives the max_steps for training. Something similar happens for eval_spec. Next, we need to define our model function, which basically defines the architecture of the neural network I'm going to use for processing the input histopathology images and detecting cancer. The model function expects to receive features to work with. So in our use case, those will be the images, the labels of the images, 0 or 1, the training mode, and the parameters dictionary, which can contain any values, but for this case, it will contain the number of classes and the learning rate for training. By the way, if you want to know more details about the model function, you can read this page from the TensorFlow documentation. What the model function does is defining the architecture of a custom convolutional neural network, or CNN. I won't go into the details of the code here, but we can see that a network consists of a convolutional layer, a pooling layer, a second convolutional layer, a second pooling layer, and finally, a flatten layer with a logits layer. After that, some more operations are performed depending on the training mode, like calculating the probabilities for each class, calculating the loss and the training accuracy. Also, you can see that Adam is being used as optimizer for this case, and the learning rate is obtained from the params dictionary. Okay, now that I have the model function, I can create an estimator in the main section of the script. For that, I'll use the TensorFlow Estimator class and pass to its constructor the model_fn, the model_dir, and the params dictionary with the number of classes and the learning rate. Next, I'll call the TensorFlow train_and_evaluate function with the classifier we just created, the train_spec and eval_spec. Finally, I'm just going to state that if the current training host is the primary host, the classifier.export_savedmodel shall be called with the sm_model_dir as output directory and the custom serving_input function, which just returns a TensorFlow serving_input receiver. By the way, if I didn't check that the current training host is the primary host before saving the trained model, every training host will save it, and that doesn't make too much sense. One more important detail I want to mention is that the training script can include two specific functions for overriding SageMaker's default behavior for processing inputs and outputs when the training model gets deployed, an input_fn for overriding input pre‑processing, and the output_fn for overriding output pre‑processing. If you don't include those functions, SageMaker will use default implementations. If you want to know more about this, you can take a look to this link. And that's it for creating a training script. Now we can proceed with creating the model for breast cancer detection using TensorFlow. The next steps for configuring TensorFlow using the high‑level SageMaker Python library are very similar to the previous demos. So I'm going to create some variables for configuring hyperparameters. I'll set the num_classes to 2, then the mini_batch_size to 128, next, the max_steps for training to 5000, and finally, the learning_rate to 0.01. Please notice that these values may not be the ones that produce the best model; however, I'm not going to worry too much about that. The important thing now is that you understand the process. Next, I'm going to create a unique job name and specify the input and the output paths for the job, configure the training instances, get the execution role, and set the train timeout. Also, we need to specify the training script path. Now we're going to create a SageMaker TensorFlow estimator, so I'm going to use the sagemaker.TensorFlow class and pass to the constructor the entry_point, which is the path to the training script, execution role, the train_ instance_count, the train_instance_type, the train_volume_size, the train_max_run, the model_dir, which is the output path, the output_path, the framework_version 1.12.0, which is the latest version, the Python version py3. This also ensures that the script mode is used for training, the hyperparameters dictionary, which is going to be passed as command‑line arguments when the training script is involved. And that's it. We have our TensorFlow estimator configured and ready to be trained for doing breast cancer detection.



demo
Configuring a MXNet Estimator Using the High-level SageMaker Python Library
Okay, time for demo, now with MXNet. We're going to see how to prepare a training script and how to configure MXNet Estimator using the high‑level SageMaker Python library. Notice that as in the TensorFlow case, we can use the low‑level AWS SDK for Python. This demo won't include the phase of converting input images to RecordIO because we have already done that when we were building a model with the building image classification algorithm. For this demo, I'm going to create a new Jupyter notebook. I'll choose conda_mxnet_p36 as the kernel and name the notebook as breast‑cancer‑detection‑with‑mxnet. First I'll import the libraries that we are going to need, which obviously includes MXNet. Next, we should convert our images to the RecordIO format because it's a more performant solution. But it turns out that we have already done that. So we can prepare the training script now. I'm going to guide you through the process of creating the script. However, I'm not going to go into every little detail of MXNet. The most important thing for now is that you understand how you can adapt your own MXNet scripts for using them in SageMaker. And obviously, your scripts don't need to be exactly the same as the one I'll be creating now. Also, if you want to get more details about using MXNet in SageMaker, you can read at this link from the SageMaker Python SDK documentation. And, well, a typical training script in MXNet does pretty much the same as a TensorFlow script, loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model so that it can be deployed for inference later. Let's start creating the training script. For that, go to the Jupyter home page and click on New, Text File. That will open a new window with the file. Make sure to rename it to mxnetScript.py. First I'll import some libraries the script is going to need, including NumPy and MXNet, and others like argparse for parsing command line arguments. Now I'll create a private function for parsing command line arguments that the script will accept. This is similar to what we did in the TensorFlow case. First I'll get the model‑dir, which is a string path on the SageMaker training host where you saved your model. Files created in this directory will be accessible in history after your SageMaker training job completes. Next, I get the train and test variables. Both variables represent the path to the directory that contains the input data for the specified channel. The default value for these variables is obtained from environment variables as well, SM_CHANNEL_TRAIN and SM_CHANNEL_TEST. Then I get the list of training hosts and the current host for training. The default values for these are also obtained from environment variables, SM_HOSTS and SM_CURRENT_HOST, similar to what we had in the TensorFlow case. Finally, I obtained some hyperparameters that the model will need, the number of classes with a default value of 2, the mini‑batch‑size with a default value of 100, the epochs with a default value of 10, and the learning‑rate with a default value of 0.1, and momentum wiht a default value of 0.9, and a wd parameter with a default value of 0.0001. And that's it for obtaining input variables for the training script. And, as with TensorFlow, the training script can accept any values we want. And SageMaker provides useful environment variables that can be used anywhere in the script. Now that we have the argument parser function, let's call it from the main _____, which is the entry point of any Python script. I'm also going to obtain some environment variables like SM_NUM_GPUS and SM_NUM_CPUS, which we are going to need later, and set a log_interval variable with a value of 1. The next function we're going to need is one that reads and decodes the RecordIO files we have previously generated for our train and test datasets. For that, the get_data function receives a path, an augment parameter to apply image augmentation or not, the number of CPUs, a batch size, the data shape, and three other optional parameters that are sent to the MXNet ImageRecordIter class. If you want to get more details about this class, you can take a look to the MXNet data loading API page. Next, I'll create two other functions named get_train_data and get_test_data. There are just simple wrappers are the get_data function for loading train and test data respectively. You can see the get_train_data expects to load a file named images_train.rec. And the get_test_data expects to load a file named images_test.rec. Then I'll create a test function that will be used when testing training accuracy of our test data. I won't get into the details of this function. I'm also going to define a save function for saving the training model when needed. Now that I have the get_train_data, get_test_data, test, and save functions, I'm going to define a train function, which will configure the neural network that's going to be used for predicting breast cancer. I'm not going to get into every detail of this function, but I'm going to explain to you the general idea of what it does. As you can see, the function will receive several parameters, including the batch_size, the number of epochs, the learning_rate, a momentum, a wd parameter, a log_interval, the number of the GPUs, the list of training hosts, and the current_host, the number of CPUs, the model_dir where the results of training are going to be stored and the directories where train and test datasets are located. Inside the function, the log level is configured to debug so we can see the draining logs. Then we have to initialize the neural network. As you can see, we are going to use the resnet_v2 network, but we are not going to use pretrained weights. If you wanted to do transfer learning, you will set the pretrained argument to true. Also, it's important to notice that the network weights are initialized with random values using Xavier initialization. Next, train and test data have to be loaded. You've seen the get_train_data and get_test_data functions we have already defined. Something important here is that I'm stating that the input shape for the network will be 3 by 224 by 224. That's because the resnet_v2 network expects images three channels, red, green, and blue, and with a size of 224 by 224 pixels. But if you remember, the histopathology images size is 3 by 50 by 50. That's why I'm using the resize parameter with a value of 224, so images get scaled to have the expected size. Then I'm creating a trainer object, which allows us to specify the optimizer that's going to be used for training. For this case, sgd is going to be used with its corresponding hyperparameters, learning rate, momentum and wd. Next, I'm going to initialize a metric variable for measuring model accuracy and define the loss function, which in this case is going to be SoftmaxCrossEntropyLoss. Then we have the training log, which loads train data in batches and updates the neural network weights for minimizing the loss. Also notice that at the end of epoch, the trained model is saved if the accuracy improves. For that, the save function we have previously created is called. Now that we have the train function, I'm going to call it from the main section of the training script with its corresponding parameters. Finally, I'm going to define two more functions that are going to be needed when deploying the trained model. The fist one, called model function, is the function that SageMaker will call for loading our trained model. If a model function is not provided, SageMaker will use a default one. And, as you can see, it expects the model_dir as parameter, which is where the results of training get stored. The other one, called transform function, is a function that SageMaker will call for reading input data, providing that data to the neural network for getting a prediction and then returning it. If a transform function is not provided, SageMaker will use a default one. As you can see, it expects four parameters, the neural network or model, the input data, the input content type, and the output content type. Something interesting is that we can use content types to vary input output handling. But here we're just going to assume JSON for both. By the way, instead of creating a custom transferring function that reads input, gets a prediction, and returns it, you can operate the three separate functions, input function, predict function, and output function. If you want more details about this, you can find them on this link. And that's it for creating the training script. Now we can proceed with creating the model for breast cancer detection using MXNet. The next steps for configuring MXNet using the high‑level SageMaker Python library are very similar to previous demos. So I'm going to create some variables for configuring hyperparameters. I'll set the number of classes to 2, then the mini batch size to 128. Next the epochs to be 2, and finally the learning rate to 0.01. As I've mentioned before in other demos, please keep in mind these values may not be the ones that produce the best model. However, I'm not going to worry too much about that. The important thing now is that you understand the process. Next, I'm going to create a unique job name, specify the input and the output paths for the job, configure the training instances, get the execution role, and set the train timeout. Also, we need to specify the training_script_path. Now we're going to create a SageMaker MXnet estimator. So I'm going to use the SageMaker MXNet class and pass through the constructor the entry point, which is the path through the training script, the execution role, the train_instance_count, the train_instance_type, the train_volume_size, the train_max_run, the output_path, the framework_version 1.3.0, which is the latest version, the Python version, py3, The hyperparameters dictionary, which is going to be passed as command line arguments when the training script is invoked. And that's it. We have our MXNet estimator configured and ready to be trained for doing breast cancer detection.

To train a model in AWS SageMaker, you have to create a training job. In the previous module when we were building our machine learning models for breast cancer detection using the built‑in Image Classification algorithm, TensorFlow, and MXNet, what we were actually doing is preparing the training jobs we were going to create in this module. A training job has several configurations. For example, the URL of the S3 bucket containing training data, the compute resources for training, the URL of the S3 bucket where the job output will be stored, the Elastic Container Registry for the training code, and, if you remember, we have already configured these parameters in the previous module. So, we have everything ready for creating training jobs. Once you have created a training job, you can monitor and analyze its progress, so let's see now how to do that in SageMaker. And if you're wondering why do we need to monitor the progress of our training jobs? Well, it's very important because, as Peter Drucker once said, "If you can't measure it, you can't improve it." So, how can we monitor our training jobs in SageMaker? It turns out we can use AWS CloudWatch for this because it collects raw data from training jobs and processes it into readable, near real‑time metrics. It's important to note that these statistics are kept for 15 months. So, a training job is an iterative process. Typically, it computes several metrics. These metrics help diagnose whether the model will generalize well or not. The training algorithm writes the values of these metrics to logs. So, what SageMaker does is monitor those logs and it sends them to AWS CloudWatch in real time. CloudWatch processes those logs, extracts metrics, and creates graphs you can view. Also, the training instances, which are the instances where training jobs get executed, report their own metrics, including CPUUtilization, MemoryUtilization, GPUUtilization, GPUMemoryUtilization, and DiskUtilization. Now, if you're wondering whether metrics are reported by the built‑in Image Classification algorithm, the answer is that two metrics are reported named train:accuracy and validation:accuracy. And what about metrics reported by the custom TensorFlow and MXNet algorithms? Well, metrics are defined at the moment of configuring the estimators. By the way, we haven't included anything about metrics when configuring the TensorFlow and MXNet estimators in the previous model. But don't worry, we're going to take care about that in this module. I've mentioned before that SageMaker monitors logs and sends them to AWS CloudWatch in real time, but how does SageMaker know which logs have to be sent? Well, the rule is pretty simple. Anything an algorithm container sends to stdout or stderr is also sent to AWS CloudWatch Logs. In CloudWatch, training logs are grouped under the aws/sagemaker/TrainingJobs log group, and the logs of each training job are assigned to a log stream whose name reflects the name of the training job itself, the instance number in the cluster of training instances where the logs are coming from, and the timestamp.

Creating and Monitoring a Training Job for the Built-in Image Classification Algorithm Using the Low-level AWS SDK for Python
Okay, time for the first demo on this module. I'm going to show you how to create and monitor a training job for the building image classification algorithm, using the low‑level AWS SDK for Python. So for this demo, I'm going to open the breast‑cancer‑detection‑with‑image‑classification‑low‑level Jupyter Notebook we have already created on the previous module. In case you have previously stopped the notebook instance, you'll need to rerun all the cells we have created on the previous module. That's my case, so I'll rerun everything, clicking on Cell, Run All Ablove. Just for remembering, on the previous module, we have created a dictionary named training_params that the low‑level AWS SDK for Python will understand for creating a training job. This dictionary contains several parameters, the TrainingJobName, the TrainingInputMode, the RoleArn, the InstanceCount, InstanceType, and VolumeSizeInGB, the input channels for training and validation, the S3OutputPath, the HyperParameters, and the StoppingCondition. Now for creating a training job, I'm going to execute the following code. First, I'm going to create a sagemaker boto3.client, then I can just simply call the create_training_job method on the sagemaker_client with the training_params dictionary. Next, I'll include some code for confirming the training job has started. For that, I can use the describe_training_job method on the sagemaker_client. Next, I'll include a waiter using the get_waiter method on the sagemaker_client. Notice the waiter will wait until the training job is completed or stopped. Once the job finishes, we can get its status again so we know if the job ended successfully or not. Finally, I'm including code for handling the case when a training job fails to start. In that case, we can show the FailureReason obtained from the describe_training_job method. A typical case when a training job fails to start is when there is another job with the same name because training job names have to be unique. By the way, if you want to get more details about the Boto3 SageMaker API, you can take a look at this link. Once we execute the code, a message is displayed stating that the Training job current status is InProgress. Then, if you go to the SageMaker service in the AWS console to the Training jobs menu, you will see a list of training jobs and their statuses. The training job we have just created is in the list with the status of InProgress. If you click on the training job name, you will see a lot of information about it. In the Job settings section, the Job name, its Status where you can see a View history link. If you click on it, you will see a history of events that have occurred on the instance so far, the Training duration, which will be empty if training hasn't completed, the ExecutionRole, the ARN of the training job, the Creation time, the Last modified time. In the Algorithm section, the Training Image, the Training Instance type, the Training Instance count, the storage volume size, the Maximum runtime, the Input mode. In the Input data configuration section, you can see information about the train and validation channels, including the Channel name, the Content type, the Compression type, the S3 data type, the S3 URI, and the S3 data distribution type. In the Metrics section, you can see this job emits four metrics to CloudWatch, which basically are related to the train and validation accuracy. Also, you can see the regular expression that SageMaker uses for parsing logs and extracting metrics. In the Output data configuration section, you can see the S3 output path and if encryption is applied. Next, you can see the Hyperparameters. Then, in the Network configuration section, we can see no custom VPC settings are applied. Next, we have the Monitor section. I'm going to talk in detail about that in a while. Then, in the Output section, you will see the location history of the model artifact that generated when training completes. At the beginning, these will be empty. Finally, there's a Tags section. In our case, we haven't configured any tags for the job. One of the steps of the job is training, you can monitor it. If you go to the Monitor section, you will see several drafts showing metrics about the training instance itself. Then, if you click on View logs, a new page showing the AWS CloudWatch service will be opened. There, you'll see the log stream corresponding to the training job, and if you click on the log stream name, you'll be able to see the logs emitted by the training job. The training logs contain a lot of useful information. For example, you can see the configuration of the training job, whether transfer learning is being used or not, whether multilabel classification is enabled or not, the hyperparameters and evolution of classification accuracy, a string is executed. Now if you go back to the Monitor section on the Training job page and click on View algorithm metrics, a new page showing the AWS CloudWatch service will be opened. This time, you'll be able to see a nice chart displaying values of the algorithm metrics, which basically are training and validation accuracy. This chart is very useful because you can see if training and validation accuracy are improving on each epoch or not. Back on the Monitor section, if you click on View instance metrics, another page showing the AWS CloudWatch service will be opened, and you'll see a chart containing information about metrics of the training instance itself. Once the training job ends, you can see its status changes to Completed. You'll be able to see the training duration as well. If you go to the Jupyter Notebook, you'll also see a message saying the training job ended with the status of Completed. Now, if you go to the Output section in the Training job page, you'll see a link to the model artifact that was generated and stored in S3 as the result of training. If you click on the link, you'll see the artifact in S3. You can also obtain the S3 URI of the model artifact from Jupyter. For that, I'm going to execute the describe_training_job method once more. Having this URI is very important because that's what we are going to need when deploying the model artifact so it can predict breast cancer. And that's it for now. We have successfully trained the model we have built based on the built‑in image classification algorithm, using the low‑level AWS SDK for Python. On the next demo, we're going to do something similar, but using the high‑level SageMaker Python library. So, see you there.

Creating and Monitoring a Training Job for the Built-in Image Classification Algorithm Using the High-level SageMaker Python Library
On this demo, we are going to see how to create and monitor a training job for the built‑in image classification algorithm, but this time using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑image‑classification high‑level Jupyter Notebook we have already created on the previous module. In case you have previous stopped the notebook instance, you'll need to re‑run all the cells we have created on the previous module. That's my case. so I will run everything, clicking on cell, Run All above. Just for remembering. on the previous module, we have created a SageMaker estimator with a series of parameters; the training image, the execution role, the train instance count, the train instance type, the train volume size, the train max run, which basically is the train timeout, the output path, and the SageMaker session. I'll just add one more parameter to the estimator, because I didn't include it when we configured it on the previous module. The parameter is the input mode, and I'll set it to Pipe. If we don't do this, the fail mode will be used when training, and we know that it's not very efficient. Now for creating a training job, I'm going to execute the following code. First, I'll create two new variables named s3_input_train and s3_input_validation. These are just objects that contain information about the s3 path and the content type for training and validation data, respectively. For example, for creating the s3_input_train object, you have to supply the s3 data argument, which on this case will be the input_train variable we have already defined on the previous module. And then you have to supply a content type, which on this case will be the application/x‑recordio, because as you remember, our input images are stored as recordio files on s3. Something similar is done for s3_input_validation. Next, you have to call the fit method on the estimator. First, you have to supply a dictionary containing the s3 paths of the train and validation channels. These are variables we have just created above, and think the job name. Once the fit call is executed, you'll be able to see the training job logs directly in the notebook. This is great compared to the previous demo where we used the low‑level AWS SDK, and we couldn't see the training job logs in the notebook. Also, if you go to the SageMaker service in AWS console to the Training jobs menu, you will see the list of training jobs and their statuses. The training job we have just created is in the list with a status of In Progress. And as you already know, if you click on the training job name, you will see a lot of information about it, which is the same information we have seen on the previous demo. Similar to the previous demo, once the status of the job is training, you can monitor it. If you go to the Monitor section, you will see several drafts showing metrics about the training instance itself. Then, if you click on View logs, a new page showing the AWS CloudWatch service will be opened, and you will be able to see the training logs. These logs are exactly the same as the ones you see on the Jupyter Notebook. Also, you can view algorithm metrics clicking on View algorithm metrics just like on the previous demo; the same for viewing instance metrics. Once the training job ends, you can see its status changes to Completed. If you go to the Jupyter Notebook, you'll also see a message saying the training job completed. And finally, if you go to the Output section in the Training job page, similar to the previous demo, you'll see a link to the model artifact that was generated and stored in history as a result of training. And that's it for now. We have successfully trained the model we have built based on the built‑in image classification algorithm by using the high‑level AWS SDK for Python. On the next demo, we are going to see how we can train the model we have built using a custom TensorFlow algorithm. See you there.

Creating and Monitoring a Training Job for the Custom Tensorflow Algorithm Using the High-level SageMaker Python Library
Time for another demo. Let's see now how to create and monitor a training job for the custom TensorFlow algorithm we have created on the previous module using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑tensorflow Jupyter notebook we have already created on the previous module. In case you have previously stopped the notebook instance, you'll need to rerun all the cells we have created on the previous module except the ones for converting images to the TFRecord format. That's my case so I'll just run the first cell where libraries are imported and look for the cell that says Creating a model using Tensorflow and click on Cell, Run All Below. Just for remembering, on the previous module, we have created a TensorFlow estimator with a series of parameters, the entry_point, execution role, the train_instance_count, the train_instance_type, the train_volume_size, the train_max_run, which basically is the train_timeout, the model_dir, the output_path, the framework_version, the py_version, and the hyperparameters. One more parameter I'll add to the TensorFlow estimator that I didn't include before is metric_definitions, which is an array of metrics you want SageMaker to extract from training logs. For this case, I'll just define a loss metric. I'll now specify the regular expression that is needed for extracting its value from logs. Now for creating a training job, I'm going to execute the following code. As you can see, it's just a simple call to the fit method on the estimator. First, you have to supply a dictionary containing these three paths of the train and validation channels. These are the input_train and input_test variables that are already defined above and then the job_name. Once the fit call is executed, you'll be able to see the training job logs directly in the notebook. This is because, as on the previous demo, we're using the high‑level SageMaker Python library and not the low‑level AWS SDK for Python. Also, if you go to the SageMaker service in AWS console to the Training jobs menu, you will see the list of training jobs and their statuses. The training job we have just created is in the list with the status of InProgress. And as you already know, if you click on the training job name, you will see a lot of information about it, which is almost the same information we have seen on the previous demo. There are just some differences. The training image, which you can clearly see that is for training with TensorFlow. The input mode, which is set to File on this case. Pipe mode will also be used, but I wanted to use file mode this time. The metrics, which is loss this time and is the metric we have defined when configuring the estimator and the hyperparameters. Similar to the previous demo, once the status of the job is training, you can monitor it. If you go to the Monitor section, you'll see several graphs showing metrics about the training instance itself. Then, if you click on View logs, a new page showing the AWS CloudWatch service will be opened, and you'll be able to see the training logs. These logs are exactly the same as the ones you see on the Jupyter notebook. Also, you can view algorithm metrics, clicking on View algorithm metrics, just like on the previous demo, and the same for viewing instance metrics. Once the training job ends, you can see the status changes to Completed. If you go to the Jupyter notebook, you'll also see a message saying the training job completed. And finally, if you go to the Output section in the training job page, similar to the previous demo, you'll see a link to the model artifact that was generated and stored in S3 as the result of training. And that's it for now. We have successfully trained the model we have built based on a custom TensorFlow algorithm. On the next demo, we are going to see how we can train the model we have built using a custom MXNet algorithm. See you there.

Creating and Monitoring a Training Job for the Custom MXnet Algorithm Using the High-level SageMaker Python Library
On this demo, we're going to see how to create and monitor a training job for the custom MXnet algorithm we have created on the previous module using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑mxnet Jupyter Notebook we have already created on the previous module. In case you have previously stopped the notebook instance, you'll need to re‑run all the cells we have created on the previous module. That's my case so I just click on cell, Run All Above. Just for remembering, on the previous module, we have created the MXnet estimator with a series of parameters; the entry point the execution role, the train instance count, the train instance type, the train volume size, the train max run, which basically is a train timeout, the output path, the framework version, the Python version, and the hyperparameters. One more parameter allowed to the MXnet estimator that I didn't include before is metric definition, which is an array of metrics we want SageMaker to extract from training logs. For this case, I'll justify a validation accuracy metric, and I'll specify the regular expression that is needed for extracting its value from logs. Now for creating a training job, I'm going to execute the following code. As you can see, it's just a simple call to the fit method on the estimator, like what we did on the TensorFlow case. First, you have to supply a dictionary containing these three parts of the string and validation channel. These are the input string and input test variables that are already defined above, and then the job name. Once the fit call is executed, you'll be able to see the training job logs directly in the notebook. This is because as on the previous demo, we're using the high‑level SageMaker Python library and not the low‑level AWS SDK for Python. Also, if you go to the SageMaker service in the AWS console to the Training jobs menu, you will see the list of training jobs and their statuses. The training job we have just rated is in the list with a status of, In Progress. And as you already know, if you click on the training job name, you will see a lot of information about it, which is almost the same information we have seen on the previous demo. There are just some differences. The training image, which you can clearly see that it is for training with MXnet, the metrics, which is validation accuracy this time, and is the metric we have defined when configuring the estimator, and the hyperparameters. Similar to the previous demo, once the status of the job is training, you can monitor it. If you go to the Monitor section, you will see several drafts showing metrics about the training instance itself. Then, if you click on View logs, a new page showing the AWS CloudWatch service will be opened and you'll be able to see the training logs. These logs are exactly the same as the ones you see on the Jupyter Notebook. Also, you can view algorithm metrics, clicking on View algorithm metrics, just like on the previous demo. The same for Viewing instance metrics. Once the training job ends, you can see its status changes to Completed. If you go to the Jupyter Notebook, you'll also see a message saying the training job completed. And finally, if you go to the Output section in a Training jobs page, similar to the previous demo, you'll see a link to the model artifact that was generated and stored in history as a result of training. And that's it for now. We have successfully trained the model we have built based on a custom MXnet algorithm. On the next section, we are going to discuss about how SageMaker can help us to improve the accuracy of our models. See you there.


Creating and Monitoring a Tuning Job for the Built-in Image Classification Algorithm Using the Low-level AWS SDK for Python
Well, it's demo time. I'm going to show you how to create and monitor a tuning job for the built‑in Image Classification algorithm, using the low‑level AWS SDK for Python. For this demo, I'm going to open the breast cancer detection with image classifications low‑level Jupyter notebook again. In case you have previously stopped the notebook instance, you'll need to rerun all the cells work have created, except the ones for the defining the training programs dictionary and creating a training job. That's my case, so we'll go to the putting it all together cell and click on Cell, Run All Above. Now for creating a tuning job, the first step will be creating a tuning job configuration dictionary, which includes the following fields, ParameterRanges. This field is where you define the hyperparameters to automatically tune. For that, you need to include the ranges of values each hyperparameter can have. ParameterRanges has three subfields, one for each of the categorical, integer, and continues hyperparameter ranges. You can define up to 20 hyperparameters to search over. So for this case, I'm defining one categorical hyperparameter to tune, which is the optimizer, and I'm stating that only sgd and adam will be allowed. Then I'm defining a continuous hyperparameter, the learning rate. And because it's a continuous variable, I'm stating the minimum and maximum values allowed. Finally, I'm defining an integer hyperparameter, which is the mini batch size, and I'm also defining the minimum and maximum values allowed. Next, in the ResourceLimits field, you have to define a maximum number of training jobs and the maximum parallel training jobs. This is because when a training job is created, what it does is creating several training jobs with different hyperparameter values, according to what you define in the parameter ranges field, for finding the hyperparameters combination that produces the best results. So MaxNumberOfTrainingJobs defines how many training jobs the tuning job is going to create. And MaxParallelTrainingJobs defines how many training jobs can ran simultaneously. For this case, I'm saying that just two training jobs should be created, and that the two of them can run simultaneously. Obviously, for getting better results, you should run more training jobs, so the tuning job has more opportunities for finding the best hyperparameters combination. But the important thing for now is that you get idea of how automatic hyperparameter optimization works. Next, the strategy field defines how the tuning job will search for the best hyperparameters combination. This can have two possible values, random, where hyperparameters tuning chooses a random combination of values from within the ranges that you specify for hyperparameters for each training job it launches. Bayesian, that treats hyperparameter turning like a regression problem, giving a set of input features, the hyperparameters, hyperparameter turning optimizes a model for the metric that you choose. By the way, if you want to read more about this, you can take a look through this link. So for this case, I'm choosing a Bayesian strategy. Finally, you have to define the hyperparameter tuning job objective, which is the metric that a tuning job has to optimize. First, you have to define the name of the metric to be optimized. For the image classification algorithm, the only metric that can be optimized is validation accuracy, By the way, if you're wondering how I know that, you can take a look through this link. Next, you have to define the optimization type, which can be minimized or maximized. For this case, we need to maximize the validation accuracy. So that's the value I'm going to choose. The next step for creating a tuning job is defining the training parameters that will be common to all the training jobs that a tuning job will launch. So we need to define a training params dictionary like when we created a training job. It's very similar to the training params dictionary we have defined before. The only two differences are we don't define a training job name because the tuning job is going to take care of assigning a name to each training job it creates. Instead of defining a hyperparameters field, we define a StaticHyperParameters field, which has all the hyperparameter values we have defined above in the notebook, except the ones we have indicated we want to tune. So not including the optimizer, the learning rate, or the mini batch size here. Finally, I'm going to define a unique job name for the tuning job. The logic is the same as used when creating a name for training jobs. However, there is a difference. A tuning job name must have length less than or equal to 32. Otherwise, the tuning job creation will fail. So I'm changing the job name prefix to bcd tuning. Bcd stands for breast cancer detection. Then for launching the tuning job, you have to obtain an instance of boto3 SageMaker client, and then you have to call the create_hyper_parameter_tuning_job method on the SageMaker client with the following parameters. The HyperParameterTuningJobName, which will be the job_name variable we have already defined above. Then the HyperParameterTuningJobConfig, which is the tuning_job_config dictionary we have just created. Finally, the TrainingJobDefinition, which is the training programs dictionary we have just created. After executing the create_hyper_parameter_tuning_job method, if everything went okay, you are going to receive a response with a HTTP status code of 200. And if you go to the SageMaker service in the AWS console and open the Hyperparameter tuning jobs menu, you'll see the tuning job that has just been created with the status of InProgress. Also you can see that no training jobs have been completed ye. When you click on the tuning job name, a new page is displayed, showing a lot of interesting information. In the hyperparameter tuning job summary section, you can see the tuning job name, the tuning job ARN, its status, the approximated training duration, the execution role, the creation time, and the last modified time. Next, you can see the training jobs that the tuning job creates. First, you can see how many training jobs have completed successfully, how many are in progress, how many were stopped, and how many failed. Next, you have the training job list, and if you click on a training job a name, you'll be able to see the training job information. This is the same we have seen when we created individual training jobs, so you can go to the Monitor section and view algorithm metrics, view training logs, and view instance metrics. Back to the tuning job page, if you click in the Job configuration tab, you'll be able to see all the configuration that has been applied to the tuning job. In the Tuning job configuration section, you can see the objective metric, the optimization strategy, the optimization type, if training job early stopping is enabled, on this case, it's off. If early stopping is enabled, each training job will be stopped earlier for avoiding over fitting. The maximum total training jobs, the parallel training job count, the maximum training runtime in seconds. Next, in the Training job configuration section, you can see the training image, the training instance type, the training instance count, the storage volume size, the input mode, and the maximum runtime. In the Input data configuration section, you can see information about the train and validation channels, including the channel name, the content type, the compression type, test related type, the S3 URI, and the S3 data distribution type. In the Output data configuration section, you can see the S3 output path, and if encryption is applied. Then in another configuration section, we can see no custom VPC settings are applied. Then, if you click on the Hyperparameter configuration tab you can see the tuning_objective_metric, which is validationaccuracy. Next, you have the hyperparameters values, and if a hyperparameter is tunable you can see the possible values it can have. This is the case of learning_rate, mini_batch_size, and optimizer. Now, if you click on the Tags tab, you'll see tags that have been assigned to the tuning job, in this case, I haven't assigned any. Finally, if you go to the Best training job tab, you'll see a message saying that best training job summary data is available when you have completed training jobs that are emitting metrics. So we have to wait all the training jobs to complete before we can see anything here. Okay, once all the training jobs are completed, the tuning job is also completed, and the best training job section will show the job that achieved the best value for the objective metric, which in this case was validation accuracy. You can also see the hyperparameters that were used for achieving that accuracy. So the static hyperparameters that we configured when defining the training jobs configuration have the values we provided. However, the hyperparameters that we defined as tunable have been adjusted by the tuning job. And if you click on the best training job name, you'll be able to see this through path of the model artifact that has been generated as the result of training. And that's it for now. We have successfully created a tuning job, which has found the best hyperparameters combination for training our breast cancer detection model based on the built‑in Image Classification algorithm using the low‑level AWS SDK for Python. On the next demo, we are going to do something similar, but using the high‑level SageMaker Python library. So see you on the next one.

Creating and Monitoring a Tuning Job for the Built-in Image Classification Algorithm Using the High-level SageMaker Python Library
On this new demo, I'm going to show you how to create and monitor a tuning job for the built‑in Image Classification algorithm by using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑image‑classification‑high‑level Jupyter Notebook again. In case you have previously stopped the notebook instance, you'll need to rerun all the cells we have created except the last one where the estimator fit call is executed because that will create a training job. So I'll go to that cell and click on Cell, Run All Above. So at this point, we should have an estimator which contains all the configurations for creating training jobs. And we're going to provide that to the tuning job we are about to create. Now for creating a tuning job, the first step will be defining the tuning configuration for the job. This is very similar to what we did on the previous demo. But for this case, I'm going to create separate variables for the hyperparameter_ranges, which is a dictionary where keys are hyperparameter names and values are ranges. Ranges are defined as objects, which can be ContinuousParameter, IntegerParameter, or CategoricalParameter. I haven't imported these classes before, so I'm going to do that now. And also, I'll import a HyperparameterTuner class I'm going to need later. Then, you need to define the objective metric name, the objective type, the maximum number of training jobs the tuning job will create, and a maximum number of parallel training jobs. Next, I'm going to define a unique job name for the tuning job. This is exactly the same as on the previous demo. Then, we have to define a HyperparameterTuner, which receives the following parameters, the estimator, which contains the information for creating training jobs, the objective_metric_name, the hyperparameter_ranges, the objective_type, the max_jobs, and the max_parallel_jobs. Then, for launching the tuning job, you have to call the fit method on the tuner. First, you have to supply a dictionary containing these three parts of the train and validation channel, these are the variables we have created above, and then the job name. As you can see, this is exactly the same as calling the fit method on the estimator, but this time, we're calling fit on the tuner. I'm also including a call to the wait method on the tuner, so the notebook waits until the tuning job is done. Now, if you go to the SageMaker service in the AWS console and open the Hyperparameter tuning jobs menu, you'll see the tuning job that has just been created with a status of InProgress. Also, you can see that no training jobs have been completed yet. When you click on the tuning job name, you'll get exactly the same information we got on the previous demo. Nothing changes. You can go to each training job and take a look to the Monitor section. So you can view algorithm metrics, view training logs, and view instance metrics. Now I just wait the tuning job to complete. Once all the training jobs are completed, the tuning job is also completed. And the Best training job section will show the job that achieved the best value for the objective metric, which on this case was validation:accuracy. This is similar to what we saw on the previous demo, and that's it for now. We have successfully created a tuning job, which has found the best hyperparameters combination for training our breast cancer detection model based on the built‑in Image Classification algorithm, but this time using the high‑level SageMaker Python library. On the next demo, we are going to see how we can create a tuning job for finding the best hyperparameters combination for a custom TensorFlow algorithm. See you there.

Creating and Monitoring a Tuning Job for the Custom Tensorflow Algorithm Using the High-level SageMaker Python Library
Let's see now how to create and monitor a tuning job for the custom TensorFlow algorithm we have created on the previous module using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑tensorflow Jupyter notebook again. In case you have previously stopped the notebook instance, you'll need to rerun all the cells we have created except the ones for converting images to the TFRecord format and the last one where the estimator fit call is executed because that will create a training job. After running the mentioned cells, we should have a TensorFlow estimator, which contains all the configurations for creating training jobs, and we are going to provide that to the tuning job we are about to create. Now for creating a tuning job, the first step will be defining the tuning configuration for the job. This is very similar to what we did on the previous demo. We have the hyperparameter_ranges. For this case, I'm just going to tune the learning_rate, which is a ContinuousParameter. I haven't imported that class before, so I'm going to do that now. And also I'll import the HyperparameterTuner class I'm going to need later. Then, you need to define objective_metric_name, which on this case will be loss. If you remember, that's the only metric we have defined when creating the TensorFlow estimator, the objective_type, which on this case will be minimize because we need to minimize the loss, the maximum number of training jobs the tuning job will create, and the maximum number of parallel training jobs. Next, I'm going to define a unique job name for the tuning job. This is exactly the same as on the previous demo. Then, we have to define a hyperparameter tuner, and this is almost the same as on the previous demo. We have to pass the estimator, which contains the information for creating training jobs, the objective_metric_name, the hyperparameter_ranges, the objective_type, the max_jobs, and the max_parallel_jobs. One difference with the previous demo is that now we need to provide the metric_definitions dictionary as well, which is the same we provided to the TensorFlow estimator. Then, for launching the tuning job, you do to have to call the fit method on the tuner. First, you have to supply a dictionary containing these three paths of the train and ventilation channels, these are variables we have created above, and then the job name. As you can see, this is exactly the same as calling the fit method on the estimator, but this time we're calling fit on the tuner. I'm also including a call to the wait method on the tuner, so the notebook waits until the tuning job is done. Now, if you go to the SageMaker service in the AWS console and open the Hyperparameters tuning jobs menu, you'll see the tuning job that has just been created with a status of InProgress. Also, you can see that no training jobs have been completed yet. When you click on the tuning job name, you'll get the same information we got on the previous demo, just with some differences. For example, in the Job configuration tab, you can see that the objective metric is loss, the optimization type is minimize. As always, you can go to each training job and take a look to the Monitor section so you can view algorithm metrics, view training logs, and view instance metrics. Now I'll just wait for the tuning job to complete. Once all the training jobs are completed, the tuning job is also completed, and the Best training job section will show the job that achieved the best value for the objective metric, which on this case was loss. And that's it for now. We have successfully created a tuning job, which has found the best hyperparameters combination for training our breast cancer detection model based on our custom TensorFlow algorithm using the high‑level SageMaker Python library. On the next demo, we're going to see how we can create a tuning job for finding the best hyperparameters combination for our custom MXNet algorithm. So see you in the next one.

Creating and Monitoring a Tuning Job for the Custom MXnet Algorithm Using the High-level SageMaker Python Library
On the final demo of this module, let's take a look at how to create and monitor a tuning job for the custom MXNet algorithm we have created on the previous module using the high‑level SageMaker Python library. For this demo, I'm going to open the breast‑cancer‑detection‑with‑mxnet Jupyter Notebook again. In case you have previously stopped the notebook instance, you'll need to rerun all the cells we have created except the last one where estimator.fit call is executed because that will create a training job. So I'll go to that cell and click on cell Run All Above. After running dimension cells, we should have MXNet estimator, which contains all the configurations for creating training jobs. And we're going to provide that to the tuning job we're about to create. Now for creating a tuning job, the first step will be defining the tuning configuration for the job. This is very similar to what we did on the previous demo. We have the hyperparameter_ranges. For this case, I'm just going to tune the learning‑rate, which is a ContinuousParameter. I haven't imported that class before, so I'm going to do that now. And also I'll import the HyperParameterTuner class I'm going to need later. Then you need to define the objective_metric_name, which on this case will be Validation‑accuracy. If you remember, that's the only metric we have to find when creating the MXNet estimator. The objective_type, which in this case will be maximize because we need to maximize the Validation‑accuracy, the maximum number of training jobs the tuning jobs will create, and the maximum number of parallel training jobs. Next, I'm going to define a unique job name for the tuning job. This is exactly the same as on the previous demo. Then we have to define a hyperparameter tuner. We have to pass the estimator, which contains the information for creating training jobs, the objective_metric_name, the hyperparameter_ranges, objective_type, the max_jobs, the max_parallel_jobs, and the metric_definitions dictionary, which is the same we provided to the MXNet estimator. Then for launching the tuning job, you have to call the fit method on the tuner. First, you have to supply a dictionary containing the three parts of the train and validation channels. These are the variables we have created above, and then the job_name. As you can see, this is exactly the same as calling the fit method on the estimator. But this time we're calling fit on the tuner. I'm also including a call to the wait method on the tuner so the notebook waits until the tuning job is done. Now, if you go to the SageMaker service in AWS console and open the Hyperparameter tuning jobs menu, you'll see the tuning job that has just been created with a status of InProgress. Also, you can see that no training jobs have been completed yet. When you click on the tuning job name, you'll get the same information we got on the previous demo just with some differences. For example, in the Job configuration tab, you can see that the objective metric is Validation‑accuracy and optimization type is Maximize. As always, you can go to each training job and take a look through the Monitor section. So you can view algorithm metrics, view training logs, and view instance metrics. Now I'll just wait for the tuning job to complete. Once all the training jobs are completed, the tuning job is also completed. In the Best training job section, we show the job that achieved the best value for the objective metric, which in this case was Validation‑accuracy. And that's it for now. We have successfully created a tuning job which has found the best hyperparameter's combination for training our breast cancer detection model based on our custom MXNet algorithm using the high‑level SageMaker Python library.



Deploying and Testing the Trained Model Based on the Built-in Image Classification Algorithm Using the Low-level AWS SDK for Python
And, well, it's time for the first demo on this module. I'm going to show you how to deploy and test the model based on the built‑in image classification algorithm that we have already trained using the low‑level AWS SDK for Python. As a first step, I'm going to open the breast‑cancer‑detection‑with‑image‑classifications‑low‑level Jupyter Notebook we have already created previously. In case you have previously stopped the notebook instance, please make sure to rerun the first cell for importing required libraries. Now what we're going to do is deploying the best model found by that unique job we have run on the previous module. First, we need to obtain the execution role on the hosting image URI for image classification. That is the URI of the Docker image that contains the code for serving a model for predictions. Then I'll define a unique modern name with the prefix of bcd‑image‑classification‑low‑level. Next, we have to create a model from training output, meaning the model artifacts. For this, I'm going to instantiate Boto 3 SageMaker client. Next, the model_artifacts_s3_path contains the S3 path of the model artifacts obtained from the tuning job. Just for remembering, you can obtain this path if you go to the SageMaker console and go to the Hyperparameter tuning jobs menu. Look for the correspondent tuning job, click on the best training job name, and go to the Output section. Now we can invoke the create_model method of the sagemaker_client, which expects the model name, the execution role, and the primary container variable, which is a dictionary that contains the hosting_image URI and the model_artifacts_s3_path. By the way, if you want to get more information, you can take a look to this link. Finally, I'll print the ModelArn for reference. After you execute the code, a model should be created. You can see it if you go to the Models menu in SageMaker console. Next, we have to create an endpoint configuration. For that, you have to create a unique endpoint configuration name. Then I'll set some variables for configuring the hosting instances, meaning what type of how many instances we want our model to be deployed to. By the way, the instance_type an instance_count don't need to be the same as the training instances. As you can see on this case, I'm using one ml.m4.xlarge instance instead of ml.p2.xlarge, which we used for training. After that, you can invoke the create_input_conflig method of the sagemaker_client. You have to pass the endpoint conflig name and the list of production variants. I know you must be wondering what a production variant is. Well, the idea is that you can deploy multiple variants of a model to the same SageMaker endpoint. This is useful for testing variations of a model in production. For example, if you have deployed a model into production and want to test a variation of the model, you can direct a small amount of traffic, say 5%, to the new model. To do this, you will have to define two production variants. On this case, I'm just going to create one production variant. For that, you have to provide a variant name, which in this case will be AllTraffic, the instance type, the instance count, and the name of the model we have created above. By the way, if you want to get more information, you can take a look to this link. Finally, I'll print the endpoint configuration name and ARN for reference. After you execute the code, an endpoint configuration should be created. You can see it if you go to the Endpoint configurations menu in SageMaker console. Finally, we can create an endpoint. For that, we have to define a unique endpoint name. Next, you have to invoke the create_endpoint method of the sagemaker_client, which expects the endpoint name and the endpoint configuration name. Also, I'll print the endpoint name and ARN for reference. After you execute the code, an endpoint should be created. You can see it if you go to the Endpoints menu in SageMake console. If you click on endpoint name, you'll see it has a Status of Creating. Also, you can see the endpoint URL. Now, if you execute this code in the notebook, you'll be able to see the status of the endpoint is creating as well. The notebook will wait until the endpoint status changes. Finally, the endpoint status will be printed again. If the status isn't InService, an exception will be thrown. After the endpoint is successfully created and in service, we can test the deployed model. For that, I logged in an instance of the sagemaker_runtime_client first. Then I'll define a predict_breast_cancer function, which expects an image_path and opens the corresponding histopathology image, then calls the invoke_endpoint method of the sagemaker_runtime_client, which expects an endpoint name, a content type, which in this case must be application/x‑image, and the image. Next, it reads the JSON response that is obtained from the endpoint. It will contain the probabilities for the 0 and 1 classes, so I'll print those. Then it calculates the predicted_class, which is the class with a higher probability. For that, I'm using the argmax function from NumPy. And finally, if the predicted_class is 0, it brings a message saying no breast cancer was detected. Otherwise, breast cancer was detected. By the way, you have to import the JSON and NumPy libraries for this function to work correctly. Now I'll call the predict_breast_cancer function with an image we know that corresponds to a case with no breast cancer. If you remember, we have all the images in our notebook instance in the images directory. All the images inside the 0 subdirectory correspond to no breast cancer. When the function is executed, the image is open and sent to the endpoint, which retrieves the probabilities for each class. And you can see the first probability which corresponds to the 0 class is higher, so breast cancer was not detected as suspected. Finally, we can do the same with an image we know that corresponds to case with breast cancer. On this case, you can see the second probability which corresponds to the 1 class is higher, so breast cancer was detected as expected. And that's it. Our endpoint is working correctly, ready to receive histopathology images and predict breast cancer. I have tested with just one image of each class, but obviously, we could test with more images and see if results are accurate. If not, we could train our model again. One more optional step. If you don't want to use your endpoint anymore, you can delete it by executing the following code. This is very important because you get charged while the endpoint is up, even if you are not using it. Then, if you want to create an endpoint again, you can recreate it from the endpoint configuration we have built. Another way of deleting the endpoint is going to the Endpoints menu in the AWS console, selecting the endpoint, and clicking on Actions, Delete. On the next demo, we're going to see this deployment process again, but using the high‑level SageMaker Python library. See you there.

Deploying and Testing the Trained Model Based on the Built-in Image Classification Algorithm Using the High-level SageMaker Python Library
Let's take a look now at how to deploy and test the model based on the built‑in Image Classification algorithm that we have already trained, but using the high‑level SageMaker Python library this time. As a first step, I'm going to open the breast‑cancer‑detection‑with‑image‑classification‑high‑level Jupyter Notebook we have already created previously. In case you have previously stopped the notebook instance, please make sure to rerun the first cell for importing required libraries. Now what we're going to do is deploying the best model found by the tuning job we have ran on the previous module. First, we need to obtain the execution role and the hosting_image URI for Image Classification. This is the same as on the previous demo. Then, similar to the previous demo, I'll create some variables for configuring hosting instances. Also, I'll define a unique model name with a prefix of bcd‑image‑classification‑high‑level. Next, we have to create a model object, which will contain information about the name of the model we're about to create, the model_artifacts_s3_path, which you can obtain if you go to the SageMaker console and go to the Hyperparameter tuning jobs menu. Look for the corresponding tuning job, click on the best training job name, and go to the Output section. The hosting_image URI, execution role, and the predictor_class, which is just a function that returns a predictor object. This function will be invoked when deploying the model. So after deployment, we get a predictor we can use for the detecting breast cancer. By the way, for this code to work correctly, you have to import the Model and RealTimePredictor classes. For more information about the Model class, you can take a look to this link. Also, for more information about real‑time predictor and other predictors, you can see these other links. Then, I'm going to create a unique name for the endpoint we will create. And then, we can create a model, an endpoint configuration, and an endpoint all at the same time. This is a very nice advantage compared to the low‑level SDK where we needed to take several steps for accomplishing the same result. So we need to call the deploy method of the model object. It expects the endpoint_name, the instance_count, and the instance_type. Also, you can see the deploy method returns a predictor object. When executing this, the endpoint creation process will start. And if you go to the SageMaker console, you'll be able to see that a model, an endpoint configuration, and an endpoint were created and that the endpoint has a status of Creating. After the endpoint is successfully created and in service, we can test the deployed model. For that, I'll define a predict_breast_cancer function, which is very similar to the previous demo. So it will print the probabilities of 0 and 1 classes for a given image and if breast cancer was detected or not. The only difference is that for obtaining a prediction from the endpoint, we can call the predict method on the predictor object with an image. By the way, you have to import the JSON and NumPy libraries for this function to work correctly. Now I'll call the predict_breast_cancer function with an image we know that corresponds to a case with no breast cancer. You can see the first probability, which corresponds to the 0 class is higher. So breast cancer was not detected as expected. Finally, we can do the same with an image we know that corresponds to a case with breast cancer. On this case, you can see the second probability, which corresponds to the 1 class is higher. So breast cancer was detected as suspected. And that's it. Our endpoint is working correctly, ready to receive histopathology images and predict breast cancer. And remember that if you don't want to use your endpoint anymore, you can delete it by executing the following code. On the next demo, we're going to see how we can deploy our training model for the custom TensorFlow algorithm using the high‑level SageMaker Python library. See you there.

Deploying and Testing the Trained Model Based on a Custom Tensorflow Algorithm Using the High-level SageMaker Python Library
On this new demo, let me show you how to deploy and test the model we have trained on the previous module based on a custom TensorFlow algorithm using the high‑level SageMaker Python library. As a first step, I'm going to open the breast‑cancer‑detection‑with‑tensorflow Jupyter Notebook we have already created previously. In case you have previously stopped the notebook instance, please make sure to rerun the first cell for importing required libraries. Now, what we are going to do is deploying the best model found by the tuning job we have ran on the previous module. First, we need to obtain execution_role. Then similar to the previous demo, I'll create some variables for configuring hosting instances. And I'll define a unique model name with a prefix of bcd‑image‑classification‑tensorflow. Next, we have to create a model object, which will contain information about the name of the model we are about to create, the model_artifacts_s3_path, which, as we have seen before, you can obtain If you go to the SageMaker console and go to the Hyperparameter tuning jobs menu, look for the corresponding tuning job, click on the best training job name, and go to the Output section. The execution role, and for this code to work correctly, you have to import the Model class. Notice this is not the same Model class as on the previous demo, but a more TensorFlow‑specific version. Then I'm going to create a unique name for the endpoint we will create, and then we can create a model, an endpoint configuration, and an endpoint, all at the same time. For that, as on the previous demo, we need to call the deploy method of the model object, which expects then the name, the instance_count, and the instance type. Also, you can see the deploy method returns a predictor object. When executing these, the endpoint creation process will start. And if you go to the SageMaker console, you'll be able to see that a model, an endpoint configuration, and an endpoint were created. After the endpoint is successfully created and in service, we can test the deployed model. For that, l'll define a predict_breast_cancer function, which, on this case, receives an image as a numpy array. And why is that? Well, if you open the custom TensorFlow script we have created on a previous module and take a look to the serving_input function, you'll see it expects to receive an array with a shape of 50 x 50 x 3, meaning images of 50 x 50 pixels with 3 channels, red, green, and blue. So the image is sent to the predictor and it returns a response, which is an object, which contains probabilities of the 0 and 1 classes and the predicted class for the given image. I'll just print a response so we can take a look to it. Next, probabilities will be printed and also if breast cancer was detected or not. Now for calling the predict_breast_cancer function, I'll need to have images loaded as a numpy array. And, well, it turns out we already have code for that. So I'll go upto the beginning of the notebook and run the cells for loading image labels in an all_image_labels array and for loading images in a dataset array. Now that I have the images and their labels loaded, I can execute the following cells for obtaining an image with no cancer and other with cancer. So I can call the predict_breast_cancer function with image_with_no_cancer now. You can see that I received a response from the endpoint and that the first probability, which corresponds to the 0 class is higher, so breast cancer was not detected as expected. Finally, we can do the same with image_with_cancer. On this case, you can see breast cancer was not detected either, but that wasn't expected. So probably we need to retrain our model for obtaining more accurate results. And that's it. Remember that if you don't want to use your endpoint anymore, you can delete it by executing the following code. By the way, you must import SageMaker for it to work correctly. On the next demo, we're going to see how we can deploy our training model for the custom MXNet algorithm using the high‑level SageMaker Python library. See you there.

Deploying and Testing the Trained Model Based on a Custom Mxnet Algorithm Using the High-level SageMaker Python Library
Now let's see how to deploy and test the model we have trained on the previous module based on a custom MXNet algorithm using the high‑level SageMaker Python library. As a first step, I'm going to open the breast‑cancer‑detection‑with‑mxnet Jupyter Notebook we have already created previously. In case you have previously stopped the notebook instance, please make sure to rerun the first cell for importing required libraries. Now what we are going to do is deploying the best model found by the tuning job we have run on the previous module. First, we need to get the execution role. Then similar to the previous demo, I'll create some variables for configuring hosting instances. Then, I'll need a variable containing the path to the custom MXNet training script we have already created. Also, I'll define a unique model name with a prefix of bcd‑image‑classification‑mxnet. Next, we have to create a model object, which will contain information about the name of the model we are about to create, the model_artifact_s3_path, which, as we have seen before, you can obtain if you go to the SageMaker console and go to the Hyperparameter tuning jobs menu, look for the corresponding tuning job, click on the best training job name, and go to the Output section, the execution role, the Python version to make sure Python 3 is used, and the entry point, which is the training_script_path. Notice that for this code to work correctly, you have to import the MXNetModel class. Then, I'm going to create a unique name for the endpoint we will create. And then we can create a model, an endpoint configuration, and an endpoint, all at the same time. For that, as on the previous demo, we need to call the deploy method of the model object, which expects the endpoint name, the instance_count, and the instance_type. Also, you can see the deploy method returns a predictor object. When executing these, the endpoint creation process will start. And if you go to the Sagemaker console, you'll be able to see that a model, an endpoint configuration, and an endpoint were created. After the endpoint is successfully created and in service, we can test the deployed model. For that, I'll define a predict_breast_cancer function, which receives a filename and reads the corresponding image as a numpy array using the read_image auxiliary function. Then, the image is sent to the predictor, and it returns a response. On this case, it contains the predicted_class, and we can use it directly to print a message, saying whether breast cancer was detected or not. And if you're wondering why we're getting the predicted_class directly in the response unlike previous demos, it's just because if you look to the transform_fn in our custom training script, you can see it's returning the predicted_class only and not other probabilities. Remember, transform_fn is the function that SageMaker will call for reading input data, providing that data to the neural network we have defined on the script for getting a prediction and then returning it. Now I'll call the predict_breast_cancer function with an image we know that corresponds to a case with no breast cancer. You can see breast cancer was not detected as expected. Finally, we can do the same with an image we know that corresponds to a case with breast cancer. On this case, you can see breast cancer wasn't detected either, which is unexpected. So probably we need to retrain our model for obtaining more accurate results. And that's it. Remember that if you don't want to use your endpoint anymore, you can delete it by executing the following code. By the way, you must import SageMaker for it to work correctly. On the next section, we're going to discuss about how we can integrate SageMaker endpoints with AWS API Gateway and AWS Lambda so we have an internet‑facing REST API for doing breast cancer detection from histopathology images that can be invoked from external applications. Excited? I know I am. So see you on the next one.


I'm going to show you an overview of how the sample REST API for breast cancer detection shall work. So, the REST API for breast cancer detection is already deployed in AWS SageMaker, and they'll just call it from Postman. By the way, I'm using Postman's 7.0.9 on a Mac, and they already have a preconfigured request for calling the REST API. Don't worry about the details of how the API was created or how the request is made right now. We'll get to it later in this course. When the request gets executed, this image will be sent to the REST API. It is a histopathology image of a patient who doesn't have breast cancer. It is a very small image with a resolution of 50 x 50 pixels. And, if you're wondering about where I have obtained this image, don't worry, I'll let you know when we start building our models in SageMaker. So, I'll just send the request right now. And as you can see, I'm getting a response that says the image we have just sent doesn't correspond to a breast cancer case, as we expected. So the API is working okay. 

