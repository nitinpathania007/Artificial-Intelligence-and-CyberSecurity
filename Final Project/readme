
Youtube Video Link
https://www.youtube.com/watch?v=XSpcuAhaejY

Fooling Machine Learning Image Classifier

Why is machine learning exciting? That's because there's so much research going on in this field. 
There are new applications and new ideas, which crop up almost every day, and generative adversarial networks, or GANs, is one 
such new idea. This new type of machine learning system, which was invented in 2014, and it relies on two neural networks 
contesting in a game as adversaries. Each neural network tries to outdo the other, and GANs in this way can be used to generate 
realistic images and videos of virtually anything. It depends on what you train it to do. 
The term adversarial here refers to the fact that there are two neural networks involved, and they're contesting against one 
another as adversaries. The two neural networks have different objectives that are orthogonal to one another. 
The first neural network tries to generate realistic images and videos to fool the second neural network, 
and the objective of the second neural network is to not get fooled. This competition steadily 
improves the abilities of both of the networks involved, and the result is that the images and 
videos generated using this network are very, very realistic. 

GANs are used in a variety of different applications today, AI-generated art, human image synthesis, generating 3D models from 
2D images, improving the astronomical image, and also in traditional machine learning models, 
such as classification and regressions. GANs belong to a category of machine learning algorithms 
called generative models. GANs are used to generate new data which are realistic in nature. 
For example, traditional classification would be considered a discriminative model. 
Discriminative models try to discriminate between inputs or classify inputs into categories.

Generative adversarial networks are considered to be part of unsupervised learning.
So when you're training you're GAN, you'll find that we won't feed in the labels for your
training data. We'll only feed in the data itself. GAN models learn by self-identifying patterns 
and logical groupings that exist in the data itself without the help of labels.
The first generative adversarial network was originally proposed and developed by Ian Goodfellow and 
a number of other researchers in the year 2014. Machine learning models and neural networks have, 
of course, been around for many years. GANs are a relatively new idea. GANs involve two neural 
networks competing in a game, and these two neural networks have specific names. We have a generated
network, which is responsible for generating realistic data and a discriminative network, which is 
responsible for identifying real data from fake data. 

The key to understanding how GANs work is understanding how these two networks compete against one another. 
The generative network, also called the generator, generates candidates of data that are as realistic as possible. 
The generative network is often compared to an art forger or a currency counterfeiter. 
The objective of the generator is to generate currency or art that is as realistic as possible and can fool experts. 
The kind of candidates that you want your generator to create depends on your training data. 
The expert that the generative network seeks to fool is the discriminative network. 
The discriminative network evaluates candidates. These candidates can be the fake data generated by 
the generative network or data from the real database. A common analogy for the discriminative network 
is that of a currency or art expert who can tell the difference between real notes and counterfeits or
real art and fake art. So how are these neural networks set up, and how do they compete against one another? 

The big picture architecture diagram of the components involved in a generative adversarial network, 
the generator, as well as the discriminator. There seems to be lots of components here and lots of interconnections.
Here is the generator network responsible for generating fake samples. You feed in some random latent noise into the generator. 
These noise variables serve as an input to this network. The generator uses this input to generate samples that are as realistic 
as possible. In addition to the fake samples generated by this generative network, we also need real data, or real samples. 
So you'll have a database of real-world images, and you'll use samples from this real-world database as well. 
Both the fake and the real data are then fed into the discriminative network. You can imagine that the discriminator 
acts as a classification algorithm, and it's responsible for identifying real data from fake data. The output of the
discriminator is real or fake. Do these images or videos come from the real database, or are they fakes created by the
generator network? The objective of the discriminator is to classify as many of the real samples as possible as real and
fake samples as fake, and all of these components put together make up the big picture architectural overview of a generative 
adversarial network. 

I'll now quickly summarize what we know about the two neural networks involved in a GAN.
A generator is responsible for generating data as realistically as possible, and we'll train the generator
to generate data that is similar to the corpus of the real data that we have. The objective of the training 
process of the generator is to improve what it creates. The generator seeks to fool the discriminator. 

On the other hand, the discriminator or the discriminative network seeks to identify real data from fake data. 
The output of the discriminator is the probability that the data that is fed in is genuine. The training process
of the discriminator classifies the output of the generator, as well as the real-world images, and the objective 
of the discriminator is to perform this classification as accurately as possible. And in this respect, this is just 
like a traditional classification model. 

Now the generator in order to create the realistic fake data needs some kind of input to work with, and which is where the noise
that we feed into a GAN comes in. When building and training our GAN model we'll use a function that generates noise. 
The corpus of data that we use to train this network, that is the training data, is composed of real data points, 
as well as the noise function, real images, as well as noise.

Training a GAN
Now that we have a big picture understanding of how generative adversarial networks work, let's move on to how these networks will be trained. We have the latent space variables used to generate noise. This is the input that the generator uses to generate fake samples. We also feed in samples of the real data, and both of these are passed into a discriminator, which classifies it as real or fake. 

We'll start off by taking a look at the steps involved in training a GAN. The training data corpus is made up of real data points, as well as a noise function. The noise function provides the input to the generator, which then generates fake samples from this noise. The generator and the discriminator will be trained simultaneously, but their objectives are different. We'll train the discriminator to tell apart the dell data and the fake data. We'll then continue to generate new noise points, and the generator will use this noise to produce data to fool the discriminator. We'll specify an appropriate loss function, which we'll talk about more in just a bit, and we'll update model parameters using an optimizer. For as many epochs of training that you specify, we'll iteratively repeat this process and improve the parameters of both the generator, as well as the discriminator model. Because both the discriminator and the generator have different objectives, the loss that we specify for these need to be different. 

The discriminator maximizes the probability of real data being classified as real and tries to minimize the probability of fake data being classified as real. And the loss function that we use has to reflect this. 

The generator, on the other hand, has a competing orthogonal objective. It seeks to maximize the probability of fake data being classified as real. In practice, we can use the same loss function for both of the models, and we need optimizers for both networks, an optimizer to update the parameters of the generator, as well as the discriminator. 

The loss function that's commonly used in practice is binary cross-entropy loss. Now all classification models which output probabilities use cross-entropy loss, which is a measure of the distance between two probability distributions. The binary cross-entropy loss is simply a variant that is optimized for binary classification. Here, the classification is binary, real or fake, so BCE loss makes sense. Another important reason why BCE loss works well is that it heavily penalizes incorrect classifications. So if the discriminator consistently classifies real data as fake or vice versa, it has a very heavy penalty and it improves faster. 

Thus, a GAN model involves training the generator and discriminator simultaneously, and they serve as adversaries during training. They both have different objective functions. During the training process, both of the models will continuously improve, and at some point, the generator will generate very, very realistic data and consistently fool the discriminator.

Understanding the Leaky ReLU Activation Function
We'll train a GAN model on the breast cancer image sets. And in the generative network, we'll use the Leaky ReLU activation.I'll discuss how the Leaky ReLU activation works and how it can help you prevent dead or unresponsive neurons. Imagine that you have a neural network where you feed in your training data and have the neurons learn from your data. Now during the training process, it's quite possible that the weights of the interconnections between your neurons do not change in response to the inputs that you specify. If you're tracking the loss of your neural network for different epochs of training, you might find that the loss stops falling and it stays the same. This means that the neurons in your network are no longer learning from your data. Neurons may be dead or unresponsive. And whether a neuron is responsive or not basically depends very heavily on the activation function that you've chosen for your neuron. Now there are a variety of activation functions available in the real world, and the choice of activation function that you make for your neural network is an important part of your neural network design. Observer that there is a gradient, or an active portion, for every activation function. This will become important in just a bit. Let's consider one of these activation functions. This is a sigmoid, S-shaped, activation function. This is the logic activation function, the one that is used in logistic regression. Observe that the maximum and minimum values of the output of this function are 1 and 0 respectively. There are several regions in this activation function. if your activation function operates in this region, when you change the input, the output will change correspondingly, so changes in the input will change the output when the neuron is in the active region. But as you move away from this active region for the sigmoid activation function, observe that the activation function saturates at either end. If your activation function happens to be operating in these regions, even when you tweak the values of your input, the output does not change. Now if it so happens that during the training process if your inputs are such that the neuron is operating within these saturation regions of the activation function, that neuron will be unresponsive. So even as you keep changing your inputs, the output of the neuron does not change. That is a dead neuron. And dead or unresponsive neurons are bad because those neurons are not learning from the data that you're feeding in. As you work more and more with neural networks, you'll find that this is a problem that you'll encounter quite often in the real world. Your neurons might become unresponsive because they're operating in the saturation regions of their activation function. As the input changes, the output does not change. Now it's possible that during training, a neuron might be in the saturation region for a while, but it snaps out of it. But if it continues throughout training that the neuron operates in the saturation region, that neuron is considered dead. Now you might have observed that different activation functions have different shapes, so saturation occurs at different regions for these activation functions. So if you're using an S-curve or a sigmoid activation function, saturation occurs at both ends. So with an S-curve, if the output of your neuron is at both ends of this S-curve, that's when it is operating in the saturation region. But for the ReLU activation, the saturation region is actually different. Here on the right, you can see the shape of the ReLU function. You can see that this activation function is active for all input values greater than 0, but it saturates for negative values. So in summary, you might say that the logic activation function saturates for very large and very small values of input whereas ReLU activation saturates for very small or negative values of input. The ReLU activation function is widely used in the real world, and it gives great performance in neural networks. An improvement over the ReLU activation function is the Leaky ReLU activation. The Leaky ReLU is a modification of the original ReLU activation which mitigates the dying neuron problem of ReLU. Observe the shape of the Leaky ReLU in the diagram that you see to your left. For positive values of input, the output is the same as the input itself. That is the ReLU activation. The difference between ReLU and Leaky ReLU comes from negative values of input. For negative values, with Leaky ReLU, the output is non-zero, but very, very close to zero. Think of it as a leakage. And this little gradient that Leaky ReLU has for negative values of input is what helps mitigate the dying neuron problem. And in practice, Leaky ReLU activations have found to outperform the strict ReLU activation function. The mathematical formula of the Leaky ReLU activation function can be expressed as follows. So Leaky ReLU of x is max of x, alpha x where alpha is a hyper parameter that you specify. Now a standard value that people tend to use for alpha is 0.01. Alpha should be a small non-zero value to ensure that your neuron does not die for negative values of input.

Loading and Exploring the Breast Cancer Detection Images
we will see how we can build a generative adversarial network to generate breast cancer or no cancer images. We'll train our module on the histopathology dataset.I start off on a new notebook, and I'm going to set up the import statements for the libraries that I'll need to build a generator and discriminator network. The generative adversarial network, or GAN, that we are about to build will be trained on the GPU because it takes a long time to run training. And the batch_size that we'll use to feed in the data is 1 and 10 as you can see in two fifferent notebooks. When you're working with GANs, you'll find that there are a number of tips and tricks that allow your GANs to perform better, and one of them is to normalize the image data that you use for training so that the pixel intensities are in the range -1 to 1. That's exactly what we'll do with the histopathology images here using the mean and standard deviation 0.5. The hostopathology imageset that we'll use to train our GAN model is a publically available image dataset on kaggle. It consists of RGB images, twhere every image is 50 pixels by 50 pixels. We'll access the breast cancer images in the form of a torch dataset. This is available from the torchvision module, and we'll load this dataset from the images folder under the current working directory. When we load this dataset in the transforms that we have specified, converting all of the images to a tensor format and normalizing them using .5 as the mean and standard deviation will be applied to the histopathology images. Once this dataset has been downloaded, you'll find that a new subfolder under your current working directory called datasets has been created. The batch_size that we have specified is 1 and 10 images per batch. Let's take a look at the first batch of data, the histopathology imageset. If you print out the content of the images tensor here you will see the tensor formed out of images, and all of these images are RGB images. I'm going to make a grid of all of the images in the first batch by calling torchvision.utils .make_grid. I'll now plot this grid of histopathology images using matplotlib. I'll convert it to a NumPy format first and clip all of the pixel intensities to the range 0 to 1 so that it can be displayed in matplotlib. Let's take a look at this image grid by invoking plt.imshow. The one thing that we need to do is to transpose some of the dimensions. The first dimension, which is the output of make_grid, will be the number of channels. We need to move that over to be the last dimension before we can display this grid of images using matplotlib. And that's exactly what the np.tranpose operation does here, and here are histopathology images that we'll use to train our GAN.

Setting up the Generator and Discriminator Neural Networks
We'll now specify the parameters of the GAN model that we'll build and train. The latent_size here refers to the dimensionality of the latent variable vector that our generator will use to create fake images. The hidden_size here is the size of the hidden layers in our generator and discriminator models. The image_size here, 7500, is the size of the images in breast cancer imageset. Fifty multiplied by Fufty pixels mutiply by 3(RGB) give us 7500 pixels. The fake images created by the generator will also have the same image_size, and we'll train our model for 1 and 5 epochs. I'll first create the neural network that will act as our discriminator. This will be train to recognize whether the input image that we feed in is real or fake, whether it's a generated image or an actual image of a histopathology dataset. You can see that this discriminator is made up of linear layers with Leaky ReLU activations along with dropout. The input to the first Linear layer is the image, whether real or fake. Every image that we pass into the discriminator will be 7500 pixels. The Leaky ReLU activation function that we've used here is a variant of the commonly used ReLU activation. For the ReLU activation, when the input is less than 0, it is clamped to 0. The Leaky ReLU eliminates this zero-slope portion of the ReLU, and it greatly mitigates the problem of saturated or dead neurons during training. The training process also tends to convert faster when you're using the Leaky ReLU as opposed to the ReLU. The 0.2 number that we passed in is a number that controls the angle of the negative slope. We've also specified a Dropout layer here that will randomly turn off 50% of the neurons in any training pass. Dropout is a technique commonly used in neural networks to mitigate overfitting on the training data. The discriminator has a final Linear layer of hidden_size, and the output dimensionality of this last Linear layer is 1. The output of the discriminator will be a probability score indicating whether the input image was from the real dataset, was a real histopathology image, and was not a generated fake one. The sigmoid or logistic activation function will ensure that the output probability score is in the range 0 to 1. We'll now set up the neural network for the generator model. This model will be trained to generate new data, new images similar to images in the real dataset, similar to images of histopathology imageset. The objective of the generator is to generate data that looks real so that it can fool the discriminator. This generative network takes as its input a latent variable vector of latent size. We'll train the generator to take these input noise variables and map them to the desired data space. That is a data space of histopathology images. The first two Linear layers in this generator network are followed by ReLU activation functions, and the last Linear layer is followed by a Tanh activation function. Observe that the size of the output of the last layer is equal to image_size. These are the fake generated images that we'll feed into the discriminator. The Tanh activation function is needed to map the pixel values of the image data in the range -1 to 1. This is the same range as the real images from the histopathology imageset. With our generator and discriminator network set up, we are now ready to begin training. Before we start the training process, we'll need to copy over the model parameters to the GPU so that we run training on the GPU.

Training the Discriminator
The loss function that we'll use to train our GAN model is binary cross-entropy, or bce_loss. This is a special case of the categorical cross-entropic loss, which is commonly used in classification models. Cross entropy measures the distance between two probability distributions, and the output of classification models are probability scores. As its name implies, the binary cross-entropy loss is often used when we classify the output into two categories, and that's the case here. We want the discriminator to classify the input images as real or fake. That is a binary classification problem. The bce_loss resembles the log loss for both the generator as well as the discriminator, and the log loss is preferred in GAN models because the log loss highly penalizes classifiers that are confident about an incorrect classification. In order to train both the discriminator and the generator model, we'll use the Adam optimizer. Assign total_step to the number of batches for which we'll run training in a single epoch. This is equal to the length of the data_loader. I'll now set up a for loop to run through each epoch of training. We'll run training or a total of 1 or 5 epochs. This is something that you can, of course, change and see how your model improves. For each epoch, we'll iterate over all of the batches of images in the training data. We're only interested in the images themselves. For each batch of image data, we'll flatten the images such that they are 1D vectors. The original images are 3 by 50 by 50. This reshape operation will create a single dimensional vector for each image. Flattening these images will allow us to feed these images into the input Linear layer of our discriminator model. You also need to ensure that you copy over your image parameters to the GPU because that where we are running training. We need to have labels for the discriminator marking the input images as real images or fake images. Labels for the real data are all ones. We'll instantiate a torch tensor equal to the batch_size where all of the tensor values are ones. The labels for the fake data are all zeros. We'll use torch.zeros to instantiate a torch tensor of all zeros equal to the batch_size once again. Now using the current weights of the discriminator, we'll make a forward pass and pass these real images through the discriminator network. The output of the discriminator will be probability scores that we'll store in the outputs variable. We'll then apply the binary cross-entropy loss function to compare the output of the discriminator with the real_labels. We use the real_labels here because all of these images are real images that we've passed in through the discriminator. We'll now store the outputs of the discriminator for the real images in the real_score variable. We'll now initialize z, which is the noise input of latent_size that we'll feed into our generator network, and we'll copy over this noise to our cuda device. We'll pass these noise images into our generator model to have our generator generate fake_images. And for the current model parameters of the discriminator, we'll pass these fake_images into the discriminator as well and get the probability scores, which we'll store in the outputs variable. We'll now compare the output of the discriminator for the fake_images with the fake_labels. Remember, the fake_labels are all zeros, and we'll calculate the bce_loss. I'll now store the output of the discriminator on the fake_images in the fake_score variable. We'll now calculate the total loss by summing up the loss on the real, as well as the fake_images. Let's zero out the gradients of both the optimizer, the discriminator optimizer, as well as the generator optimizer, and we are now ready to make a backward pass through our model to calculate gradients. We calculate gradients with respect to the total loss and call d_optimizer.step. At this point, we've updated the model parameters for only the discriminator. We've made a forward pass through the discriminator with the real, as well as fake_images then made a backward pass to calculate gradients with respect to the total_loss and updated only the discriminators parameters.

Training the Generator and Generating Fake Images and Test on Image Classification Models
We'll train the generator, which'll generate fake_images. We'll generate noise variables with dimensionality latent_size and copy these noise variables over to the cuda device. Our generator will map these input noise vectors to an output in the desired space, the space of breast cancer data. We'll pass these noise variables through the generator and generate fake_images. We'll then pass these fake_images through the discriminator to see what the discriminator makes of them. The resulting output of the discriminator will be stored in the outputs variable. The objective of the generator model, as we know, is to generate fakes that fool that discriminator, which means when we calculate the generator loss, the generator network will try and get the discriminator to classify these fake_images as real. So the bce_loss will be calculated using the outputs of the discriminator on the fake data and the real_lables. Minimizing this loss function will allow the generator to generate fakes that will fool the discriminator into thinking these are real images. Note that in this loss function, we compare the output of the discriminator on the fake images with the real_labels. Zero out the gradients of both optimizers, the generator, as well as the discriminator, and go ahead and make a backward pass through the generator network with respect to the generator loss. Then call g_optimizer.step to update the model parameters of the generator network. and every 200 epochs and full dataset on differenr notebooks, we'll print out a bunch of information, the discriminator loss, generator loss, etc., to screen to see how the training is progressing. The value in the fake_images variable is the final set of fake_images created by our generator model. This is the last set of fake_images after we've trained for 1 or 5 epochs. I'm going to reshape this tensor so that it's a batch of 50 by 50 RGB images. We can then visualize these images and see what the generated images look like. Now we'll start training our GAN model. This training ran for about 12 hours because of the size of the data on the GPU, so it takes a while. Once training has run through for 1 epoch and 5 in other notebook, let's make a grid of the fake_images generated by our generator network. I'll now convert these to a format that can be displayed in matplotlib, and we'll display this grid of generated images using plt.imshow, and here is the image generated by our generator neural network. You can see that they are very close to the real dataset. I can see cancer or no cancer images that could be from the real dataset. It's pretty amazing how real these fake images are. Now we will feed these images to the image classification models. By this we were able to evade machine learning image classifiers as you can see in the notebooks that fake images are getting cancer detected also.
